---
title: A worfklow for low-level analyses of single-cell RNA-seq data
author: 
    - name: Aaron T. L. Lun
      affiliation: Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom
    - name: John C. Marioni
      affiliation: Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom; EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom
date: 29 February 2016
vignette: >
    %\VignetteIndexEntry{A worfklow for low-level analyses of single-cell RNA-seq data}
    %\VignetteEngine{knitr::rmarkdown}
output: 
    BiocStyle::html_document:
        fig_caption: yes
bibliography: ref.bib
---

```{r style, echo=FALSE, results='hide', message=FALSE}
library(BiocStyle)
library(knitr)
opts_chunk$set(error=FALSE)
opts_chunk$set(fig.width=7, fig.height=7)
opts_chunk$set(dpi=300, dev="png", dev.args=list(pointsize=15))
options(bitmapType="cairo")
```

```{r, message=FALSE, echo=FALSE, results='hide'}
library(DESeq2)
library(scran)
library(edgeR)
library(scater)
library(gplots)
library(gdata)
library(R.utils)
library(org.Mm.eg.db)
```

# Introduction

Single-cell RNA sequencing (scRNA-seq) is widely used to measure the genome-wide expression profile of individual cells.
From each cell, mRNA is isolated and reverse transcribed to cDNA for high-throughput sequencing [@stegle2015computational].
This can be done using microfluidics platforms like the Fluidigm C1 [@pollen2014lowcoverage], or with protocols based on microtiter plates like Smart-seq2 [@picelli2014fulllength].
The number of reads mapped to each gene can then be used to quantify its expression in each cell.
Alternatively, unique molecular identifiers (UMIs) can be used to directly measure the number of transcript molecules for each gene [@islam2014quantitative].
Count data can be analyzed to identify new cell subpopulations via dimensionality reduction and clustering; to detect highly variable genes (HVGs) across a population; or to detect differentially expressed genes (DEGs) between conditions.
This provides biological insights at a single-cell resolution that cannot be achieved with conventional bulk RNA sequencing of cell populations.

Strategies for scRNA-seq data analysis differ markedly from those for bulk RNA-seq.
One technical reason is that scRNA-seq data is much noisier than bulk data [@brennecke2013accounting;@marinov2014singlecell].
Reliable capture (i.e., conversion) of transcripts into cDNA for sequencing is difficult with the low quantity of RNA in a single cell.
This increases the frequency of drop-out events where none of the transcripts for a gene are captured.
Dedicated steps are required to deal with this noise, especially during quality control.
In addition, scRNA-seq data can be used to study cell-to-cell heterogeneity, e.g., to identify new cell subtypes, to characterize differentiation processes, to assign cells into their cell cycle phases, or to identify HVGs driving variability across the population [@vallejos2015basics;@fan2016characterizing;@trapnell2014dynamics].
This is simply not possible with bulk data, such that custom methods are required to perform these analyses. 

This article describes a computational workflow for basic analysis of scRNA-seq data using software packages from the open-source Bioconductor project [@huber2015orchestrating].
Starting from a count matrix, this workflow contains the steps required for quality control to remove problematic cells; normalization of cell-specific biases, with and without spike-ins; cell-cycle phase classification from gene expression data; data exploration to identify putative subpopulations; and finally, HVG and DEG identification to prioritize interesting genes.
The application of different steps in the workflow will be demonstrated on several public scRNA-seq data sets involving haematopoietic stem cells, brain-derived cells, T-helper cells and mouse embryonic stem cells, generated with a range of experimental protocols and platforms [@wilson2015combined;@zeisel2015brain;@buettner2015computational;@kolod2015singlecell].
The aim is to provide a variety of modular usage examples that can be applied to construct custom analysis pipelines.

# A simple analysis on haematopoietic stem cells

## Overview

To introduce most of the concepts of scRNA-seq data analysis, we use a relatively simple data set from a study of haematopoietic stem cells (HSCs) [@wilson2015combined].
Single mouse HSCs were isolated into microtiter plates and libraries were prepared for 96 cells using the Smart-seq2 protocol.
A constant amount of spike-in RNA from the External RNA Controls Consortium (ERCC) was also added to each cell prior to library preparation.
High-throughput sequencing was performed and the expression of each gene was quantified by counting the total number of reads mapped to its exonic regions.
Similarly, the quantity of each spike-in transcript was measured by counting reads mapped to the spike-in reference sequence.
Counts for all genes/transcripts in each cell were obtained from the NCBI Gene Expression Omnibus (GEO) as a supplementary file under the accession number GSE61533.

For simplicity, we forgo a description of the read processing steps required to generate the count matrix, i.e., read alignment and counting into features.
These steps have been described in some detail elsewhere [@love2015rnaseq], and are largely the same for bulk and single-cell data.
The only additional consideration is that the spike-in information must be included in the pipeline.
Typically, spike-in sequences can be included as additional FASTA files during genome index building prior to alignment, while genomic intervals for both spike-in transcripts and endogenous genes can be concatenated into a single GTF file prior to counting.
For users favouring a R-based approach to read alignment and counting, we suggest using the methods in the `r Biocpkg("Rsubread")` package [@liao2013subread;@liao2014featurecounts].

## Count loading and quality control

The first task is to load the count matrix into memory.
This requires some work to decompress and retreive the data from the Excel format.
Each row of the matrix represents an endogenous gene or a spike-in transcript, and each column represents a single HSC.
For convenience, the counts for spike-in transcripts and endogenous genes are stored in a `SCESet` object from the `r Biocpkg("scater")` package.

```{r}
library(R.utils)
gunzip("GSE61533_HTSEQ_count_results.xls.gz", remove=FALSE, overwrite=TRUE)
library(gdata)
all.counts <- read.xls('GSE61533_HTSEQ_count_results.xls', sheet=1, header=TRUE, row.names=1)
library(scater)
sce <- newSCESet(countData=all.counts)
dim(sce)
```

We annotate those rows corresponding to ERCC spike-ins and mitochondrial genes.
This information can be easily extracted from the row names, though in general, identifying mitochondrial genes from standard identifiers like Ensembl requires extra annotation.
We then calculate quality control metrics such as the total number of counts, the proportion of counts for the mitochondrial genes or spike-in transcripts, etc.
These metrics are stored in the `pData` of the `SCESet` for future reference.

```{r}
is.spike <- grepl("^ERCC", rownames(sce))
isSpike(sce) <- is.spike
is.mito <- grepl("^mt-", rownames(sce))
sce <- calculateQCMetrics(sce, feature_controls=list(Spike=is.spike, Mt=is.mito))
head(colnames(pData(sce)))
```

Low-quality cells are defined as those where the endogenous RNA has not been efficiently captured (i.e., converted into cDNA and amplified) during library preparation.
These can be identified as those cells with a low sum of counts for the endogenous genes.
In general, any cell with a count sum that is an order of magnitude lower than the median across all cells can be considered to be of low quality and removed.
A more relaxed threshold may need to be used when strong heterogeneity in total RNA content is expected across cells.

```{r}
endo.sum <- sce$counts_endogenous_features
summary(endo.sum)
keep <- endo.sum >= median(endo.sum)/10
sce <- sce[,keep]
sum(!keep)
```

Cells with very few expressed (i.e., non-zero) counts are also removed.
This ensures that the total count in each cell is not driven by a small number of transcripts.
Cells with fewer than 1000 expressed genes are considered to be of poor quality, as it suggests that the diverse transcript population has not been successfully captured.
Here, all cells have a reasonable number of expressed genes and so no removal is performed.

```{r}
summary(sce$total_features)
```

Another measure of quality is the proportion of reads mapped to genes in the mitochondrial genome.
High proportions are indicative of poor-quality cells [@islam2014quantitative;@ilicic2016classification], possibly because of increased apoptosis and/or loss of cytoplasmic RNA from lysed cells.
A similar case can be made for the proportion of reads mapped to spike-in transcripts.
The distributions of mitochondrial and spike-in proportions across all cells are shown in the plots below.

```{r controlplothsc, fig.width=12, fig.height=6, fig.cap="Histogram of the proportion of reads mapped to mitochondrial genes (left) or spike-in transcripts (right) across all remaining cells in the HSC data set."}
par(mfrow=c(1,2))
mito.props <- sce$pct_counts_feature_controls_Mt
hist(mito.props, xlab="Mitochondrial proportion", ylab="Number of cells", 
    breaks=20, main="", col="grey80")
spike.props <- sce$pct_counts_feature_controls_Spike
hist(spike.props, xlab="ERCC proportion", ylab="Number of cells",
    breaks=20, main="", col="grey80")
```

Defining a threshold on the proportion is not straightforward as it depends largely on the cell type and the experimental protocol.
If we assume that most cells in the data set are not apoptotic, then the threshold can be set to remove any large outliers from the distribution of proportions.
Here, we define outliers as those with proportions that are more than 3 median absolute deviations (MADs) above the median proportion.
This results in the removal of a small number of cells.

```{r}
mito.keep <- mito.props < median(mito.props) + 3*mad(mito.props)
sum(!mito.keep)
spike.keep <- spike.props < median(spike.props) + 3*mad(spike.props)
sum(!spike.keep)
sce <- sce[,mito.keep & spike.keep]
ncol(sce)
```

An alternative approach to quality control is to perform a principal components analysis (PCA) based on the quality metrics for each cell, e.g., the total number of reads, the total number of features, the proportion of mitochondrial or spike-in reads.
Outliers on a PCA plot may be indicative of low-quality cells that have aberrant technical properties compared to the (presumed) majority of high-quality cells.
Here, no cells were identified as outliers in the plot below.
This is consistent with the removal of suspect cells in the preceding quality control steps.

```{r pcaqualplothsc, fig.cap="PCA plot for all remaining cells in the HSC data set, constructed using quality metrics. The first and second components are shown on each axis, along with the percentage of total variance explained by each component. Bars represent the coordinates of the cells on each axis."}
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
plotPCA(sce, pca_data_input = "pdata", detect_outliers=TRUE) + fontsize
```

Methods like outlier detection and support vector machines can provide greater power to distinguish low-quality cells from high-quality counterparts [@ilicic2016classification].
This is because they are able to detect subtle patterns across many quality metrics simultaneously. 
However, this comes at some cost to interpretability, as the reason for removing a given cell may not always be obvious.
Thus, for this workflow, we will use the simple approach whereby each quality metric is considered separately.

## Filtering out low-abundance genes

Low-abundance genes are removed as the counts are too low for reliable statistical inferences.
In addition, the discreteness of the counts may interfere with downstream statistical procedures, e.g., by compromising the accuracy of asymptotic approximations.
Here, low-abundance genes are defined as those with an average count across cells below 1.
Removing them avoids problems with discreteness and also reduces the amount of computational work.

```{r}
keep <- rowMeans(counts(sce)) >= 1
sce <- sce[keep,] 
sum(keep)
```

An alternative approach to gene filtering is to select genes that have non-zero counts in at least _n_ cells. 
This provides some more protection against outlier expression patterns, i.e., genes with strong expression in only one or two cells. 
Such outlier patterns are typically uninteresting unless rare cells are of particular interest.
An example of this approach is shown below for _n_ set to 10.

```{r}
alt.keep <- rowSums(is_exprs(sce)) >= 10
sum(alt.keep)
```

The relationship between the proportion of expressing cells and the mean can be examined more closely in the plot below.
The two statistics tend to be well-correlated, so filtering on either should give similar results.

```{r geneplothsc, fig.cap="Frequency of expression against the mean expression for each gene. Circles represent endogenous genes and triangles represent spike-in transcripts or mitochondrial genes. The bars on each axis represent the location of each gene on that axis. Genes above high technical dropout are defined as those above a non-linear trend fitted to the triangles."}
plotQC(sce, type = "exprs") + fontsize
```

In general, we prefer the mean-based filter as it tends to be less aggressive.
A gene will be retained as long as it has sufficient expression in any subset of cells.
The "at least _n_" filter depends heavily on the choice of _n_ -- in this case, a gene expressed in a subset of 9 cells would be lost.
While the mean-based filter will retain more outlier-driven genes, this can be handled downstream by choosing methods that are robust to outliers.

## Normalization of cell-specific biases

Read counts are subject to differences in capture efficiency and sequencing depth between cells [@stegle2015computational].
Normalization is required to eliminate these cell-specific biases prior to downstream quantitative analyses.
This is often done by assuming that most genes are not differentially expressed (DE) between cells.
Any systematic difference in count size across the non-DE majority of genes between two cells is assumed to represent bias and is removed by scaling.
More specifically, "size factors" are calculated that represent the extent to which counts should be scaled in each library.

Size factors can be computed with several different approaches, e.g., using the `estimateSizeFactorsFromMatrix` function in the `r Biocpkg("DESeq2")` package [@anders2010differential;@love2014moderated], or with the `calcNormFactors` function [@robinson2010scaling] in the `r Biocpkg("edgeR")` package (this requires an additional multiplication by the library size).
However, single-cell data can be problematic for these bulk data-based methods due to the dominance of low and zero counts.
To overcome this, we pool counts from many cells to increase the count size for accurate size factor estimation [@lun2016much].
Pool-based size factors are then "deconvolved" into cell-based factors for cell-specific normalization.

```{r, warning=FALSE}
sce <- computeSumFactors(sce, sizes=c(20, 40, 60, 80))
summary(sizeFactors(sce))
```

In this case, the size factors are tightly correlated with the total counts for all cells.
This suggests that the systematic differences between cells are primarily driven by differences in capture efficiency or sequencing depth.
Any DE between cells would yield a non-linear trend between the total count and size factor, and/or increased scatter around the trend.
This does not occur here as strong DE is unlikely to exist between cells of the same type.

```{r normplothsc, fig.cap="Size factors from deconvolution, plotted against the total counts for all cells in the HSC data set. Axes are shown on a log-scale."}
plot(sizeFactors(sce), sce$total_counts/1e6, log="xy",
    ylab="Total count (per million)", xlab="Size factor")
```

Normalized log-expression values can be computed for use in downstream analyses.
Each value is defined as the log-ratio of each count to the size factor for the corresponding cell (after adding a small prior count to avoid undefined values at zero counts).
Division by the size factor ensures that any cell-specific biases are removed.
The log-transformation is also useful as larger counts can be modelled reasonably well with a log-normal distribution [@law2014voom].
The computed values are stored as an `"exprs"` matrix in addition to the other assay elements.

```{r}
sce <- normalize(sce)
```

## Data exploration with dimensionality reduction techniques

Dimensionality reduction is often useful to examine major features of the data before more quantitative analyses.
Of particular interest is whether the HSCs partition into distinct subpopulations.
This can be visualized by constructing a PCA plot from the normalized log-expression values.
Cells with similar expression profiles should be located close together on the plot.

```{r pcaplothsc, fig.cap="PCA plot constructed from normalized log-expression values, where each point represents a cell in the HSC data set. First and second components are shown, along with the percentage of variance explained. Bars represent the coordinates of the cells on each axis. None of the cells are controls (e.g., empty wells) so the legend can be ignored."}
plotPCA(sce, exprs_values="exprs") + fontsize
```

Alternatively, the PCA plot can be constructed from a matrix of correlations between cells. 
Two cells with similar expression profiles will exhibit similar patterns of correlations to other cells.
As a result, those two cells will be closer together in the plot.
This approach tends to be more robust to outliers than a standard PCA plot, as a small number of aberrant genes will have little effect on the value of Spearman's rank correlation.
However, this comes at the cost of being less sensitive to subtle differences in the expression profiles.

```{r pcacorplothsc, fig.cap="PCA plot constructed from a matrix of Spearman rank correlations between cells, where each point represents a cell in the HSC data set."}
cor.mat <- cor(assayDataElement(sce, "exprs"), method="spearman")
out <- prcomp(cor.mat)
plot(out$x[,1], out$x[,2], xlab="PC1", ylab="PC2", pch=16)
```

Another popular approach to dimensionality reduction is the _t_-stochastic neighbour embedding (_t_-SNE) method [@van2008visualizing].
_t_-SNE tends to work better than PCA for large data sets with complex substructure, at the cost of more computational effort and complexity.
Unlike PCA, _t_-SNE is a stochastic method -- users should run the algorithm several times to ensure that the results are representative, and then set a seed to ensure that the chosen results are reproducible.
It is also advisable to test different settings of the "perplexity" parameter as this will affect the distribution of points in the low-dimensional space.

```{r tsneplothsc, fig.cap="_t_-SNE plot constructed from normalized log-expression values using a range of perplexity values. In each plot, each point represents a cell in the HSC data set. Bars represent the coordinates of the cells on each axis.", fig.width=12, fig.height=6}
set.seed(100)
out5 <- plotTSNE(sce, exprs_values="exprs", perplexity=5) + fontsize + ggtitle("Perplexity = 5")
out10 <- plotTSNE(sce, exprs_values="exprs", perplexity=10) + fontsize + ggtitle("Perplexity = 10")
out20 <- plotTSNE(sce, exprs_values="exprs", perplexity=20) + fontsize + ggtitle("Perplexity = 20")
multiplot(out5, out10, out20, cols=3)
```

By default, both the `plotPCA` and `plotTSNE` functions will only use the top 500 genes with the highest variances.
This focuses on the genes that are driving heterogeneity in the population and should provide greater visual resolution of any systematic differences between groups of cells.
For this data set, all methods suggest that there is no separation into distinct subpopulations.
This is consistent with a homogenous population of cells of the same type.
Of course, there are many dimensionality reduction techniques that we have not considered here but could also be used, e.g., multidimensional scaling.

## Classification of cell cycle phase 

We use the prediction method described by @scialdone2015computational to classify cells into cell cycle phases based on the gene expression data.
Using a training data set, the sign of the difference in expression between two genes was computed for each pair of genes.
Pairs were chosen with changes in the sign across cell cycle phases.
Cells in a test data set can then be classified into the appropriate phase, based on whether the observed sign is consistent with one phase or another.
This is achieved using the `cyclone` function on a pre-trained set of gene pairs for mouse data.
(Some additional work is necessary to match the gene symbols in the data to the Ensembl annotation in the set of pairs.)

```{r phaseplothsc, message=FALSE, fig.cap="Cell cycle phase scores from applying the pair-based classifier on the HSC data set, where each point represents a cell."}
mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran"))
library(org.Mm.eg.db)
anno <- select(org.Mm.eg.db, keys=rownames(sce), keytype="SYMBOL", column="ENSEMBL")
ensembl <- anno$ENSEMBL[match(rownames(sce), anno$SYMBOL)]
keep <- !is.na(ensembl)
assignments <- cyclone(sce[keep,], mm.pairs, gene.names=ensembl[keep])
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score", pch=16)
```

Cells are classified as being in G1 phase if the G1 score is above 0.5; in G2/M phase if the G2/M score is above 0.5; and in S phase, if neither is above 0.5.
Here, the vast majority of cells are classified as being in G1 phase.
We will focus on these cells for the downstream analysis.
Cells in other phases are removed to avoid potential confounding effects from cell cycle-induced differences.
Alternatively, if a non-negligible number of cells are in other phases, we can use the assigned phase as a blocking factor in downstream analyses.
This protects against cell cycle effects without discarding a substantial amount of information.

```{r}
g1.only <- assignments$score$G1 > 0.5
sce <- sce[,g1.only]
```

Pre-trained classifiers are available in `r Rpackage("scran")` for human and mouse data. 
The mouse classifier used here was trained on embryonic stem cells but can still be generally applied -- the pair-based method is a non-parametric procedure that should be robust to technical differences between data sets, and the transcriptional program associated with cell cycling should be mostly conserved across cell types.
However, it will (inevitably) be less accurate for cell types that are substantially different from those used in the training set.
Users can also construct a custom classifier from their own training data using the `sandbag` function.
This may be necessary for other model organisms where pre-trained classifiers are not available.

## Identifying HVGs from the normalized log-expression 

We identify HVGs to focus on the genes that are driving heterogeneity across the population of cells.
This requires estimation of the variance in expression for each gene, followed by decomposition of the variance into biological and technical components.
HVGs are then identified as those genes with the highest biological components.
This avoids prioritizing genes that are highly variable due to technical factors such as sampling noise during RNA capture and library preparation.

Ideally, the technical component would be estimated by fitting a mean-variance trend to the spike-in transcripts.
Recall that the same set of spike-ins is added in the same quantity to each cell.
This means that the spike-in transcripts should exhibit no biological variability, such that any variance in the counts should be technical in origin.
Fitting is performed by the `trendVar` function, using a loess curve with a low span as the trend is highly non-linear.
(Some adjustment of the parameters may be required to obtain a satisfactory fit.)

```{r}
var.fit <- trendVar(sce, trend="loess", span=0.3)
```

Given the mean abundance of a gene, the fitted value of the trend can be used as an estimate of the technical component for that gene.
The biological component of the variance can then be calculated by subtracting the technical component from the total variance of each gene in the `decomposeVar` function.

```{r}
var.out <- decomposeVar(sce, var.fit)
```

In practice, this strategy is complicated by the difficulty of accurately fitting a complex trend to a low number of unevenly distributed points.
An alternative approach is to fit the mean-variance trend to the endogenous genes.
This assumes that the majority of genes are constantly expressed, such that the technical component dominates the total variance of expression for those genes.
The fitted value of the trend can then be used as an estimate of the technical component.

```{r}
var.fit2 <- trendVar(sce, trend="loess", use.spikes=FALSE, span=0.2)
var.out2 <- decomposeVar(sce, var.fit2)
```

We assess the suitability of the trend fitted to the endogenous variances by examining whether it is consistent with the spike-in variances. 
The former passes through the bulk of the latter in the plot below, indicating that our assumption (that most genes are not biologically variable) is valid.
In contrast, the spike-in trend is less accurate at mean intervals with few spike-in transcripts.
More generally, the use of an endogenous trend is the only option in data sets where no spike-ins were added or in situations where not enough spike-in RNA was added to cover the range of means for the endogenous genes.

```{r hvgplothsc, fig.cap="Variance of normalized log-expression values for each gene in the HSC data set, plotted against the mean log-expression. The red line represents the mean-dependent trend in the technical variance of the spike-in transcripts (also highlighted as red points). The blue line represents the trend fitted to the variances of the endogenous genes."}
plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab="Mean log-expression", 
    ylab="Variance of log-expression")
points(var.fit$mean, var.fit$var, col="red", pch=16)
o <- order(var.out$mean)
lines(var.out$mean[o], var.out$tech[o], col="red", lwd=2)
lines(var.out2$mean[o], var.out2$tech[o], col="dodgerblue", lwd=2)
```

The top HVGs are identified by ranking genes on their biological components.
This can be used to prioritize interesting genes for further investigation.

```{r}
top.hvgs <- order(var.out2$bio, decreasing=TRUE)
write.table(file="hsc_hvg.tsv", var.out2[top.hvgs,], sep="\t", quote=FALSE, col.names=NA)
head(var.out2[top.hvgs,])
```

We recommend checking the distribution of expression values for the top HVGs to ensure that the variance estimate is not being dominated by one or two outlier cells.

```{r, fig.cap="Boxplots of normalized log-expression values for the top 10 HVGs in the HSC data set. Points correspond to cells that are more than 1.5 interquartile ranges from the edge of each box."}
examined <- top.hvgs[1:10]
all.names <- matrix(rownames(sce)[examined], nrow=length(examined), ncol=ncol(sce))
boxplot(split(exprs(sce)[examined,], all.names), las=2, ylab="Normalized log-expression")
```

Of course, there are many ways of defining HVGs, e.g., by using the coefficient of variation [@kolod2015singlecell;@kim2015characterizing], through the dispersion parameter in the negative binomial distribution [@mccarthy2012differential], or as a proportion of total variability [@vallejos2015basics].
We use the variance of the log-expression values because the log-transformation provides some protection against genes with strong expression in only one or two outlier cells.
This ensures that the set of top HVGs is not dominated by genes with (mostly uninteresting) outlier expression patterns.
However, the cost of this robustness is the need to fit a complex mean-variance relationship.

## Identifying correlated gene pairs with Spearman's rho

Another useful procedure is to identify the HVGs that are highly correlated with one another.
This distinguishes between HVGs caused by random noise and those involved in driving systematic differences between subpopulations.
Gene pairs with significantly large positive or negative values for Spearman's rho are identified using the `correlatePairs` function.
Note that we only apply this function for the top set of HVGs -- doing so for all possible gene pairs would require too much computational time and may prioritize uninteresting genes that have strong correlations but low variance, e.g., tightly co-regulated house-keeping genes.

```{r}
set.seed(100)
var.cor <- correlatePairs(sce[top.hvgs[1:200],])
write.table(file="hsc_cor.tsv", var.cor, sep="\t", quote=FALSE, col.names=NA)
head(var.cor)
```

HVGs with significant correlations can be prioritized for follow-up studies.
For example, a set of correlated genes can be used as markers to validate the existence of a subpopulation of cells with a specific expression pattern, e.g., via fluorescence-activated cell sorting, immunohistology or RNA flourescence _in situ_ hybridization.
Negatively correlated pairs may be particularly useful in this respect, as they provide a clear "negative control" signal for cells outside of the subpopulation.

Significant correlations are defined by testing against the null hypothesis of no correlations, i.e., expression profiles between two genes are independent.
This yields a _p_-value representing the significance of each pairwise correlation.
Correction for multiple testing across many gene pairs is performed by controlling the false discovery rate (FDR) at 5%.

```{r}
sig.cor <- var.cor$FDR <= 0.05
summary(sig.cor)
```

Larger sets of correlated genes can be assembled by treating genes as nodes in a graph and each pair of genes with significantly large correlations as an edge.
In this manner, an undirected graph can be constructed using methods in the `r Biocpkg("RBGL")` package.
Highly connected subgraphs can then be identified and defined as gene sets.
This provides a convenient summary of the pairwise correlations between genes.

```{r, message=FALSE}
library(RBGL)
g <- ftM2graphNEL(cbind(var.cor$gene1, var.cor$gene2)[sig.cor,], W=NULL, V=NULL, edgemode="undirected")
cl <- highlyConnSG(g)$clusters
cl <- cl[order(lengths(cl), decreasing=TRUE)]
cl <- cl[lengths(cl) > 2]
cl
```

## Using correlated HVGs for further data exploration

For further analyses, we focus on the significantly correlated HVGs for which any substructure should be most pronounced.
This may allow us to identify subpopulations that would have otherwise been masked by random noise in the expression profiles..

```{r}
chosen <- unique(c(var.cor$gene1[sig.cor], var.cor$gene2[sig.cor]))
norm.exprs <- exprs(sce)[chosen,,drop=FALSE]
```

We construct a simple dendrogram to group together cells with similar expression patterns across the chosen genes.
Here, we cluster on Euclidean distances to provide greater sensitivity to differences in expression for low numbers of genes.
Ward's clustering criterion is used to minimize the total variance within each cluster.

```{r}
my.dist <- dist(t(norm.exprs))
my.tree <- hclust(my.dist, method="ward.D2")
```

In addition, subpopulations of cells can be explicitly defined from the dendrogram..
A dynamic tree cut is performed to define the clusters, using the `cutreeDynamic` function in the `r CRANpkg("dynamicTreeCut")` package [@langfelder2008defining].
Note that some tuning of `cutHeight` is required to obtain satisfactory results for each data set.

```{r}
library(dynamicTreeCut)
my.clusters <- unname(cutreeDynamic(my.tree, distM=as.matrix(my.dist), 
    verbose=0, cutHeight=60))
my.clusters
```

We can visualize this dendrogram result with a heatmap.
All expression values are mean-centred for each gene to highlight the relative expression between cells.
We recommend storing the heatmap at a sufficiently high resolution so that the relevant genes can be easily identified for further examination.

```{r heatmaphsc, message=FALSE, fig.width=7, fig.height=7, fig.cap="Heatmap of mean-centred normalized log-expression values for correlated HVGs in the HSC data set. Dendrograms are formed by hierarchical clustering on the Euclidean distances between genes (row) or cells (column). Column colours represent the cluster to which each cell is assigned after a dynamic tree cut."}
library(gplots)
heat.vals <- norm.exprs - rowMeans(norm.exprs)
heatmap.2(heat.vals[chosen,], col=bluered, symbreak=TRUE, trace='none', cexRow=0.8,
    ColSideColors=c("darkgreen", "orange", "dodgerblue", "grey80")[my.clusters+1],
    Colv=as.dendrogram(my.tree))
```

A close look suggests that a _H2-Aa_/_Cd74_-expressing subpopulation exists alongside a _Fos_/_Jun_-negative subpopulation.
_H2-Aa_ codes for a component of the class II major histocompatibility complex and may be indicative of B-cell contamination [@heng2008immunological].
_Fos_ and _Jun_ may also be relevant as they are involved in cell proliferation [@angel1991role].
In addition, these visual subpopulations roughly correspond to the computationally identified clusters from the dynamic tree cut.
Further analyses can then be performed on those empirical clusters -- for example, we could perform a DE analysis to identify marker genes for each corresponding subpopulation.

That being said, users should treat clustering results with some caution.
It is difficult to maintain statistical rigour during clustering to protect against the formation of spurious clusters.
As such, determining whether a cluster is "real" or not usually depends on subjective judgement, unless the clusters are very clearly defined (e.g., strong separation on a PCA plot, widespread differences in the expression profiles).
Moreover, different algorithms can yield substantially different clusters by focusing on different aspects of the data.
In short, experimental validation of the clustering results is critical to ensure that the putative subpopulations actually exist.

Finally, dimensionality reduction can be applied using only the set of HVGs to highlight any substructure that might be present.
This is shown below for both PCA and _t_-SNE plots, though in this case, focusing on HVGs does not provide any additional separation into distinct subpopulations.

```{r pcareduxhsc, fig.width=10, fig.height=6, fig.cap="PCA (left) and _t_-SNE plots (right) using only the expression values for significantly correlated HVGs in the HSC data set. Each cell is represented by a point in each plot, and the bars represent the cell coordinates on each axis."}
set.seed(100)
out.pca <- plotPCA(sce, exprs_values="exprs", feature_set=chosen) + fontsize
out.tsne <- plotTSNE(sce, exprs_values="exprs", feature_set=chosen) + fontsize
multiplot(out.pca, out.tsne, cols=2)
```

## Additional comments

Once the preliminary analysis is completed, it is often useful to save the `SCESet` object to file.
This means that the object can be easily restored into new R sessions for further work, without having to repeat all of the processing steps described here.
More complex analyses can then be performed on the single-cell expression data, e.g., ordering HSCs by differentiation pseudotime with `r Biocpkg("monocle")` [@trapnell2014dynamics], or characterizing cell-state hierarchies with `r Biocpkg("sincell")` [@julia2015sincell].

```{r}
saveRDS(file="hsc_data.rds", sce)
```

# A more complex analysis on brain cell types

## Overview

We proceed to tackle a more complex data set from a study of cell types in the mouse brain [@zeisel2015brain].
This contains approximately 3000 cells of varying types such as oligodendrocytes, microglia and neurons.
Individual cells were isolated using the Fluidigm C1 microfluidics system and library preparation was performed on each cell using a UMI-based protocol.
After sequencing, expression was quantified by counting the number of UMIs mapped to each gene.
Count data for all endogenous genes, mitochondrial genes and spike-in transcripts were obtained from http://linnarssonlab.org/cortex.

## Count loading 

The count data are distributed across several files, so some work is necessary to consolidate them into a single matrix.
We define a simple utility function for loading data in from each file. 
(We stress that this function is only relevant to the current data set, and should not be used for other data sets.
This kind of effort is generally not required if all of the counts are in a single file and separated from the metadata.)

```{r}
readFormat <- function(infile) { 
    # First column is empty.
    metadata <- read.delim(infile, stringsAsFactors=FALSE, header=FALSE, nrow=10)[,-1] 
    rownames(metadata) <- metadata[,1]
    metadata <- metadata[,-1]
    metadata <- as.data.frame(t(metadata))
    # First column after row names is some useless filler.
    counts <- read.delim(infile, stringsAsFactors=FALSE, header=FALSE, row.names=1, skip=11)[,-1] 
    counts <- as.matrix(counts)
    return(list(metadata=metadata, counts=counts))
}
```

Using this function, we read in the counts for the endogenous genes, ERCC spike-ins and mitochondrial genes.

```{r}
endo.data <- readFormat("expression_mRNA_17-Aug-2014.txt")
spike.data <- readFormat("expression_spikes_17-Aug-2014.txt")
mito.data <- readFormat("expression_mito_17-Aug-2014.txt")
```

We also need to rearrange the columns for the mitochondrial data, as the order is not consistent with the other files.

```{r}
m <- match(endo.data$metadata$cell_id, mito.data$metadata$cell_id)
mito.data$metadata <- mito.data$metadata[m,]
mito.data$counts <- mito.data$counts[,m]
```

```{r, echo=FALSE}
stopifnot(identical(endo.data$metadata$cell_id, spike.data$metadata$cell_id)) # should be the same.
stopifnot(all(endo.data$metadata$cell_id==mito.data$metadata$cell_id)) # should now be the same.
```

The counts are then combined into a single matrix for constructing a `SCESet` object.
For convenience, metadata for all cells are stored in the same object for later access.

```{r}
all.counts <- rbind(endo.data$counts, mito.data$counts, spike.data$counts)
metadata <- AnnotatedDataFrame(endo.data$metadata)
sce <- newSCESet(countData=all.counts, phenoData=metadata)
dim(sce)
```

We also add annotation identifying which rows correspond to each class of features.

```{r}
nrows <- c(nrow(endo.data$counts), nrow(mito.data$counts), nrow(spike.data$counts))
is.spike <- rep(c(FALSE, FALSE, TRUE), nrows)
isSpike(sce) <- is.spike
is.mito <- rep(c(FALSE, TRUE, FALSE), nrows)
```

```{r, echo=FALSE, results='hide'}
# Save some memory.
rm(mito.data, endo.data, spike.data)
gc()
```

## Quality control on the cells and genes

The original authors of the study have already removed low-quality cells prior to data publication.
Nonetheless, we can compute some metrics to check that whether the remaining cells are satisfactory.

```{r}
sce <- calculateQCMetrics(sce, feature_controls=list(Spike=is.spike, Mt=is.mito)) 
```

As previously described, we remove cells with low total counts for endogenous genes or with few total expressed features.

```{r}
endo.sum <- sce$counts_endogenous_features 
count.keep <- endo.sum >= median(endo.sum)/10
sum(!count.keep)
feature.keep <- sce$total_features >= 1000
sum(!feature.keep)
```

We also examine the distribution of the proportions of total reads mapped to mitochondrial genes or spike-in transcripts.

```{r controlplotbrain, fig.width=12, fig.height=6, fig.cap="Histogram of the proportion of reads mapped to mitochondrial genes (left) or spike-in transcripts (right) across all cells in the brain data set."}
par(mfrow=c(1,2))
mito.props <- sce$pct_counts_feature_controls_Mt
hist(mito.props, xlab="Mitochondrial proportion (%)", ylab="Number of cells", breaks=20, main="")
spike.props <- sce$pct_counts_feature_controls_Spike
hist(spike.props, xlab="ERCC proportion (%)", ylab="Number of cells", breaks=20, main="")
```

For the mitochondrial proportions, a couple of clear outliers are observed.
These are defined and removed with a MAD-based threshold as previously described.
We repeat this process to remove outlier cells with high spike-in proportions.
Note that the spike-in proportions here are more variable than in the HSC data set.
This may reflect a greater variability in the total amount of endogenous RNA per cell when many cell types are present.

```{r}
spike.keep <- spike.props <= median(spike.props) + 3*mad(spike.props)
sum(!spike.keep)
mito.keep <- mito.props <= median(mito.props) + 3*mad(mito.props)
sum(!mito.keep)
```

Removal of low-quality cells can then be performed by combining all of the metrics.
The majority of cells are retained, which suggests that the original quality control procedures were generally adequate.

```{r}
total.keep <- count.keep & feature.keep & spike.keep & mito.keep
sce <- sce[,total.keep]
summary(total.keep)
```

Low-abundance genes are also removed by applying a simple mean-based filter.
This yields fewer genes than in the HSC data set, mostly because the sequencing depth per cell is much lower.

```{r}
keep <- rowMeans(counts(sce)) >= 1
sce <- sce[keep,]
sum(keep)
```

Some data sets may contain strong heterogeneity in mitochondrial RNA content, possibly due to differences in mitochondrial copy number or activity between cell types.
This heterogeneity will cause mitochondrial genes to dominate the top set of results, e.g., for identification of correlated HVGs.
However, these genes are largely uninteresting given that most studies focus on nuclear regulation.
As such, we filter them out prior to further analysis.
Other candidates for removal include pseudogenes or ribosomal RNA/protein-coding genes that might not be biologically relevant but can interfere with interpretation of the results.

```{r}
sce <- sce[!fData(sce)$is_feature_control_Mt,]
```

```{r echo=FALSE, results='hide', message=FALSE}
gc()
```

## Normalization and cell-cycle classification

Normalization of cell-specific biases is performed using the deconvolution method in the `computeSumFactors` function.
Here, we cluster similar cells together and normalize the cells in each cluster using the deconvolution method.
This improves the accuracy of normalization by reducing the number of DE genes between cells in the same cluster.
Normalization between clusters is then performed to ensure that expression values from cells in different clusters are comparable.

```{r}
clusters <- quickCluster(sce)
sce <- computeSumFactors(sce, cluster=clusters)
sce <- normalize(sce)
```

```{r echo=FALSE, results='hide', message=FALSE}
gc()
```

Compared to the HSC analysis, more scatter is observed for the trend between the total count and size factor for each cell.
This is consistent with an increased amount of DE between cells of different types, which compromises the accuracy of library size normalization [@robinson2010scaling].
In contrast, the size factors are estimated based on median ratios and are more robust to the presence of DE between cells.

```{r normplotbrain, fig.cap="Size factors from deconvolution, plotted against the total counts for all cells in the brain data set. Axes are shown on a log-scale."}
plot(sizeFactors(sce), sce$total_counts/1e6, log="xy",
    ylab="Total count (per million)", xlab="Size factor")
```

We also attempt to classify cells into cell cycle phases using the `cyclone` method.
We use additional cores to speed up classification for data sets with many cells.
However, examination of the plot below indicates that many of the G1 and G2/M scores are ambiguous.
This highlights the potential difficulties of training a classifier on one cell type (mouse embryonic stem cells -- see @scialdone2015computational for more details) and applying it on a substantially different cell type.
Some neuron types are particularly problematic as they are postmitotic and do not belong in any phase of the cell cycle.

```{r, echo=FALSE, results='hide', message=FALSE}
mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran"))
library(org.Mm.eg.db)
```

```{r phaseplotbrain, message=FALSE, fig.cap="Cell cycle phase scores from applying the pair-based classifier on the brain data set, where each point represents a cell."}
anno <- select(org.Mm.eg.db, keys=rownames(sce), keytype="SYMBOL", column="ENSEMBL")
ensembl <- anno$ENSEMBL[match(rownames(sce), anno$SYMBOL)]
keep <- !is.na(ensembl)
assignments <- cyclone(sce[keep,], mm.pairs, gene.names=ensembl[keep], BPPARAM=MulticoreParam(5))
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score", pch=16)
```

Given the lack of definitive classification, we will not perform any processing of the data set by cell cycle phase.
However, this information is still useful for verifying downstream results.
For example, if putative subpopulations have distinctly different phase scores, we might suspect that the differences between subpopulations are being driven by cell cycle effects.

## Data exploration to examine the effect of technical factors

For large experiments, data exploration has two functions -- to identify interesting biology, and also to check the effect of various technical factors.
PCA plots constructed from the expression data suggest that distinct subpopulations are present.
Some of the substructure may be due to differences in the tissue from which the cells were extracted, e.g.,
    cells from the cortex and hippocampus dominate the bottom-right and bottom-left corners of the plot, respectively.
In contrast, cells taken from mice of different sexes mix throughout the plot, indicating that sex has little effect on the overall differences across the data set.

```{r, echo=FALSE, results='hide', message=FALSE}
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
```

```{r pcaplotbrain, fig.width=12, fig.height=6, fig.cap="PCA plots constructed from the normalized expression values for all remaining cells in the brain data set. Each cell is represented by a point in each plot, and the bars represent the cell coordinates on each axis. Left: cells are coloured according to the tissue of origin (cortex or hippocampus). Right: cells are coloured according to the sex of the mouse -- male (-1), female (1) or unassigned (0)."}
pca1 <- plotPCA(sce, exprs_values="exprs", colour_by="tissue") + fontsize
pca2 <- plotPCA(sce, exprs_values="exprs", colour_by="sex") + fontsize
multiplot(pca1, pca2, cols=2)
```

Similar results are observed with _t_-SNE plots.
Again, users should set the seed to a constant value to ensure that the results are reproducible.

```{r tsneplotbrain, fig.width=12, fig.height=6, fig.cap="_t_-SNE plots constructed from the normalized expression values for all remaining cells in the brain data set. Each cell is represented by a point in each plot, and the bars represent the cell coordinates on each axis. Left: cells are coloured according to the tissue of origin (cortex or hippocampus). Right: cells are coloured according to the sex of the mouse -- male (-1), female (1) or unassigned (0)."}
set.seed(100)
tsne1 <- plotTSNE(sce, exprs_values="exprs", colour_by="tissue") + fontsize
set.seed(100)
tsne2 <- plotTSNE(sce, exprs_values="exprs", colour_by="sex") + fontsize
multiplot(tsne1, tsne2, cols=2)
```

An additional effect to consider is the fact that cells were processed on many different C1 chips.
This can lead to batch effects due to technical differences in library preparation between chips.
To check that this is not the case, we examine the spread of cells from each chip on the PCA plot.
Cells from different chips seem to mix together, which suggests that the substructure is not being driven by a batch effect.

```{r pca2plotbrain, fig.width=15, fig.height=6, fig.cap="PCA plots constructed from the normalized expression values for all cells in the brain data set from the cortex (left) or hippocampus (right). Each cell is represented by a point in each plot, and the bars represent the cell coordinates on each axis. Cells are coloured according to the C1 chip from which the library was prepared."}
sce$chip <- sub("_.*", "", sce$cell_id)
pca1 <- plotPCA(sce[,sce$tissue=="sscortex"], exprs_values="exprs", 
    colour_by="chip") + fontsize + ggtitle("Cortex")
pca2 <- plotPCA(sce[,sce$tissue!="sscortex"], exprs_values="exprs", 
    colour_by="chip") + fontsize + ggtitle("Hippocampus")
multiplot(pca1, pca2, cols=2)
```

Note that we separate cells by tissue to avoid picking up the tissue effect in the PCA plots (as the chip factor is nested within the tissue factor).
This hierarchical approach can be extended if sufficient annotation is available.
For example, consider a situation where multiple chips were used for each mouse, and multiple mice were used in the entire experiment.
We could construct a PCA plot for cells in each mouse, coloured by the chip of origin -- this allows us to check whether chip effects are present in that mouse.
We could then construct a PCA plot for all cells, coloured by the mouse of origin -- this allows us to check whether a mouse effect is present.
This strategy reduces the complexity of the colours in each plot and improves the ease of diagnosis.

<!-- 
The prefix of the cell ID seems to be the chip, as the second half of the ID marks the well position and there's always less than 96.
It should at least be the mouse, as the prefix is nested in tissue/sex. 
-->

In summary, the major difference between cells seems to be associated with the tissue of origin.
Whether this is interesting or not is debatable as it depends on the biological hypothesis being studied.
However, for the purposes of this workflow, we will treat the tissue of origin as an uninteresting confounding effect.
As such, we will block on tissue in all of our downstream analyses.

```{r}
design <- model.matrix(~sce$tissue)
```

## Identifying correlated HVGs

We identify HVGs that may be involved in driving population heterogeneity.
This is done by fitting a trend to the technical variances for the spike-in transcripts as previously described.
We then compute the biological component of the variance for each endogenous gene by subtracting the fitted value of the trend from the total variance.

```{r}
var.fit <- trendVar(sce, trend="loess", design=design, span=0.4)
var.out <- decomposeVar(sce, var.fit)
```

```{r, echo=FALSE, results='hide', message=FALSE}
gc()
```

The plot below suggests that the trend is fitted accurately to the technical variances.
Errors in fitting seem to be negligible relative to the size of the total variances for the endogenous genes.
The technical variances are also much smaller than those in the HSC data set.
This is due to the use of UMIs which reduces the noise caused by variable PCR amplification.
Furthermore, the spike-in trend is consistently lower than the variances of the endogenous genes.
This means the previous strategy of fitting a trend to the endogenous variances would not be appropriate here (or necessary, given the quality of the spike-in trend). 

```{r, fig.cap="Variance of normalized log-expression values for each gene in the brain data set, plotted against the mean log-expression. The red line represents the mean-   dependent trend in the technical variance of the spike-in transcripts (also highlighted as red points)."}
plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab="Mean log-expression", 
    ylab="Variance of log-expression")
points(var.fit$mean, var.fit$var, col="red", pch=16)
o <- order(var.out$mean)
lines(var.out$mean[o], var.out$tech[o], col="red", lwd=2)
```

The top HVGs are are identified based on their biological components.
These are saved to file for future reference.

```{r}
top.hvgs <- order(var.out$bio, decreasing=TRUE)
write.table(file="brain_hvg.tsv", var.out[top.hvgs,], sep="\t", quote=FALSE, col.names=NA)
head(var.out[top.hvgs,])
```

Again, we check the distribution of expression values for the top 10 HVGs to ensure that they are not being driven by outliers.

```{r, fig.cap="Boxplots of normalized log-expression values for the top 10 HVGs in the brain data set. Points correspond to cells that are more than 1.5 interquartile ranges from the edge of each box."}
examined <- top.hvgs[1:10]
all.names <- matrix(rownames(sce)[examined], nrow=length(examined), ncol=ncol(sce))
boxplot(split(exprs(sce)[examined,], all.names), las=2, ylab="Normalized log-expression")
```

To identify genes involved in defining subpopulations, the top 200 HVGs can be tested for significant pairwise correlations.
These results are also saved to file for use in designing validation experiments.

```{r}
set.seed(100)
var.cor <- correlatePairs(sce[top.hvgs[1:200],], design=design)
write.table(file="brain_cor.tsv", var.cor, sep="\t", quote=FALSE, col.names=NA)
head(var.cor)
```

Correlated HVGs can also be used to construct a heatmap that can be inspected for subpopulations.
Here, we use the normalized log-expression values for the top HVGs that have significant correlations at a FDR of 5%.
We also apply the `removeBatchEffect` function from the `r Biocpkg("limma")` package [@ritchie2015limma] to remove the tissue effect.
This ensures that any differences due to the tissue of origin will not dominate the visualization of the expression profiles.

```{r}
sig.cor <- var.cor$FDR <= 0.05
chosen <- unique(c(var.cor$gene1[sig.cor], var.cor$gene2[sig.cor]))
norm.exprs <- exprs(sce)[chosen,,drop=FALSE]
library(limma)
norm.exprs <- removeBatchEffect(norm.exprs, batch=sce$tissue)
```

The plot below shows systematic differences between groups of cells with distinct patterns of expression.
This is consistent with the presence of well-defined subpopulations.
The empirical clusters also correspond roughly to the visual subpopulations, which suggests that they can be reliably used for downstream analyses. 
Greater control of the empirical clusters can be obtained by manually specifying `cutHeight` in `cutreeDynamic`.

```{r heatmapbrain, message=FALSE, fig.width=7, fig.height=10, fig.cap="Heatmap of mean-centred normalized log-expression values for correlated HVGs in the brain data set. Dendrograms are formed by hierarchical clustering on the Euclidean distances between genes (row) or cells (column). Column colours represent the cluster to which each cell is assigned after a dynamic tree cut."}
my.dist <- dist(t(norm.exprs))
my.tree <- hclust(my.dist, method="ward.D2")
my.clusters <- unname(cutreeDynamic(my.tree, distM=as.matrix(my.dist), verbose=0))
heat.vals <- norm.exprs - rowMeans(norm.exprs)
clust.col <- rainbow(max(my.clusters))
heatmap.2(heat.vals, col=bluered, symbreak=TRUE, trace='none', cexRow=0.8,
    ColSideColors=clust.col[my.clusters], Colv=as.dendrogram(my.tree))
```

This heatmap can be stored at a greater resolution for detailed inspection later.

```{r, results='hide'}
pdf("brain_heat.pdf", width=7, height=20)
heatmap.2(heat.vals, col=bluered, symbreak=TRUE, trace='none', cexRow=0.8,
    ColSideColors=clust.col[my.clusters], Colv=as.dendrogram(my.tree))
dev.off()
```

## Detecting marker genes between subpopulations

Once putative subpopulations are identified by clustering, we can identify some candidate marker genes that are unique to those subpopulations.
This is done by testing for DE between each pair of subpopulations and selecting those genes that are consistently upregulated (or downregulated) in one subpopulation compared to all others.
DE testing can be done using a number of packages, but for this workflow, we will use the `r Biocpkg("edgeR")` package [@robinson2010edgeR].
First, we set up a design matrix specifying which cells belong in which cluster.
Each `cluster*` coefficient represents the average log-expression of all cells in the corresponding cluster.
We also block on uninteresting factors such as the tissue of origin.

```{r}
cluster <- factor(my.clusters)
design <- model.matrix(~0 + cluster + sce$tissue)
colnames(design)
```

The `r Biocpkg("edgeR")` package uses negative binomial (NB) distributions to model the read counts for each sample.
We estimate the NB dispersion parameter that quantifies the biological variability in expression across cells in the same cluster.
We then fit a generalized linear model (GLM) to the counts for each gene [@mccarthy2012differential].
We log-transform the size factors and use them as GLM offsets to normalize cell-specific biases.

```{r}
y <- DGEList(counts(sce))
y$offset <- log(sizeFactors(sce))
y <- estimateDisp(y, design, robust=TRUE)
fit <- glmFit(y, design)
```

To identify marker genes for a particular cluster, we test each gene for DE between that cluster and each other cluster.
This is done using the likelihood ratio test (LRT) for each comparison, which is demonstrated below for cluster 2.

```{r}
result.logFC <- result.PValue <- list()
chosen.clust <- 2
for (clust in as.integer(levels(cluster))) {
    if (clust==chosen.clust) { next }
    contrast <- numeric(ncol(design))
    contrast[chosen.clust] <- 1
    contrast[clust] <- -1
    res <- glmLRT(fit, contrast=contrast)
    con.name <- paste0('against.', clust)
    result.logFC[[con.name]] <- res$table$logFC
    result.PValue[[con.name]] <- res$table$PValue
}
```

Potential marker genes for cluster 2 are ranked based on the maximum _p_-value across all comparisons.
A gene that is DE between the chosen cluster and all others should have small _p_-values for all comparisons, and thus a small maximum _p_-value.
In addition, we only focus on genes with the same sign of the log-fold change across all comparisons.
This is necessary to identify specific markers that are unambiguously upregulated (or downregulated) in cluster 2 relative to the other clusters.

```{r}
max.PValue <- do.call(pmax, result.PValue)
all.logFC <- do.call(cbind, result.logFC)
all.signs <- sign(all.logFC)
same.sign <- rowSums(all.signs[,1]!=all.signs)==0L
marker.set <- data.frame(Gene=rownames(y), logFC=all.logFC, 
    PValue=max.PValue, stringsAsFactors=FALSE)
marker.set <- marker.set[same.sign,]
marker.set <- marker.set[order(marker.set$PValue),]
head(marker.set)
```

We save the list of candidate marker genes for further examination.
We also examine their expression profiles to verify that the DE is not being driven by outlier cells.
The heatmap below indicates that all of the top markers are strongly expressed across most cells in cluster 2, whereas expression is lower or absent in the other clusters.
Some robustness to outliers is expected from `r Biocpkg("edgeR")`, as any outliers will inflate the dispersion and increase the maximum _p_-value for the affected genes.

```{r, fig.cap="Heatmap of mean-centred normalized log-expression values for the top set of markers for cluster 2 in the brain data set. Column colours represent the cluster to which each cell is assigned."}
write.table(marker.set, file="marker_brain_2.tsv", sep="\t", quote=FALSE, row.names=FALSE)
top.markers <- marker.set$Gene[1:20]
norm.exprs <- exprs(sce)[top.markers,,drop=FALSE]
heat.vals <- norm.exprs - rowMeans(norm.exprs)
heatmap.2(heat.vals, col=bluered, symbreak=TRUE, trace='none', cexRow=1,
    ColSideColors=clust.col[my.clusters], Colv=as.dendrogram(my.tree), dendrogram='none')
legend("bottomleft", col=clust.col, legend=sort(unique(my.clusters)), pch=16)
```

This process can be repeated for each cluster to identify markers specific to the corresponding subpopulation.
However, it must be stressed that the _p_-values cannot be interpreted as measures of significance.
This is because the clusters have been empirically identified from the data.
`r Biocpkg("edgeR")` does not account for the uncertainty and stochasticity in clustering, which means that the _p_-values are much lower than they should be. 
The (maximum) _p_-value should only be used for ranking candidate markers for follow-up studies.

## Additional comments

Having completed the preliminary analysis, we save the `SCESet` object with its associated data to file.
This is especially important here as the brain data set is quite large.
If further analyses are to be performed, it would be inconvenient to have to repeat all of the pre-processing steps described above.

```{r}
saveRDS(file="brain_data.rds", sce)
```

```{r, echo=FALSE, results='hide'}
gc()
```

# Alternative parameter settings and strategies

## Normalizing based on spike-in coverage

Scaling normalization strategies for scRNA-seq data can be broadly divided into two classes.
The first class assumes that there exists a subset of genes that are not DE between samples, as previously described.
The second class uses the fact that the same amount of spike-in RNA was added to each cell.
Differences in the coverage of the spike-in transcripts can only be due to cell-specific biases, e.g., in capture efficiency or sequencing depth.
Scaling normalization is then applied to equalize spike-in coverage across cells.

The choice between these two normalization strategies depends on the biology of the cells and the features of interest.
If there is no reliable house-keeping set, and if the majority of genes are expected to be DE, then spike-in normalization may be the only option for removing technical biases.
Spike-in normalization should also be used if differences in the total RNA content of individual cells are of interest.
This is because the same amount of spike-in RNA is added to each cell, such that the relative quantity of endogenous RNA can be easily quantified in each cell.
For non-DE normalization, any change in total RNA content will affect all genes in the non-DE subset, such that it will be treated as bias and removed.

The use of spike-in normalization can be demonstrated on the HSC data set.
We load in the `SCESet` object that we saved earlier, which contains the count data for filtered genes in high-quality HSCs.
We then apply the `computeSpikeFactors` method to estimate size factors for all cells.
This method computes the total count over all spike-in transcripts in each cell, and calculates size factors to equalize the total spike-in count across cells. 

```{r}
sce <- readRDS("hsc_data.rds")
deconv.sf <- sizeFactors(sce)
sce <- computeSpikeFactors(sce)
```

Both non-DE methods (like deconvolution) and spike-in normalization will capture technical biases such as sequencing depth and capture efficiency.
Indeed, the plot below shows a rough positive correlation between the two sets of size factors, consistent with removal of technical biases by both methods.
However, the differences between the two sets are attributable to variability in total RNA content across the HSC population.
Spike-in normalization will preserve differences in RNA content, whereas non-DE normalization will eliminate them.

```{r, fig.cap="Size factors from spike-in normalization, plotted against the size factors from deconvolution for all cells in the HSC data set. Axes are shown on a log-scale."}
plot(sizeFactors(sce), deconv.sf, pch=16, log="xy", xlab="Size factor (spike-in)",
    ylab="Size factor (deconvolution)")
```

Whether or not total RNA content is relevant depends on the biological hypothesis. 
In the analyses described above, variability in total RNA across the population was treated as noise and removed by non-DE normalization.
This may not always be appropriate if total RNA is associated with a biological difference of interest.
For example, @islam2011characterization describe a 5-fold difference in total RNA between mouse embyronic stem cells and fibroblasts.
Spike-in normalization will preserve this difference and may provide more accurate quantification in downstream analyses.

## Blocking on the cell-cycle phase

Cell cycle phase is usually uninteresting in studies focusing on other aspects of biology.
However, the effects of cell cycle on the expression profile can mask other effects and interfere with the interpretation of the results.
This cannot be avoided by simply removing cell cycle marker genes, as the cell cycle can affect a substantial number of other transcripts [@buettner2015computational].
Rather, a more sophisticated strategy is required -- this is demonstrated below using data from a study of T Helper 2 (Th2) cells [@mahata2014singlecell].
@buettner2015computational have already applied quality control and normalized the data, so we can use them directly as log-expression values.

```{r}
library(openxlsx)
incoming <- read.xlsx("nbt.3102-S7.xlsx", sheet=1, rowNames=TRUE)
sce <- newSCESet(exprsData=t(incoming))
```

We empirically identify the cell cycle phase using the pair-based classifier.
The majority of cells in the plot below are assigned to the G1 or G2/M phases, with small numbers of cells in S-phase or without clear assignments.

```{r, echo=FALSE, results='hide', message=FALSE}
mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran"))
library(org.Mm.eg.db)
set.seed(100)
```

```{r phaseplotth2, message=FALSE, fig.cap="Cell cycle phase scores from applying the pair-based classifier on the Th2 data set, where each point represents a cell."}
anno <- select(org.Mm.eg.db, keys=rownames(sce), keytype="SYMBOL", column="ENSEMBL")
ensembl <- anno$ENSEMBL[match(rownames(sce), anno$SYMBOL)]
keep <- !is.na(ensembl)
assignments <- cyclone(exprs(sce)[keep,], mm.pairs, gene.names=ensembl[keep])
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score", pch=16)
```

The assignment for each cell can be explicitly defined by applying a threshold of 0.5 on the scores.

```{r}
hard.assign <- rep("S", ncol(sce))
hard.assign[assignments$score$G1 > 0.5] <- "G1"
hard.assign[assignments$score$G2M > 0.5] <- "G2M"
hard.assign[assignments$score$G1 > 0.5 & assignments$score$G2M > 0.5] <- "unknown"
sce$assignments <- hard.assign
table(hard.assign)
```

We then use `removeBatchEffect` to remove the effect of the (empirical) cell cycle phase on the gene expression profiles.
The result of this procedure can be visualized with some PCA plots in the image below.
Before removal, cells in the G1 and G2/M phases tend to be concentrated in different parts of the plot.
Afterwards, more intermingling is observed between the phases which suggests that the cell cycle effect has been mitigated.

```{r pcaplotth2, fig.width=10, fig.height=6, fig.cap="PCA plots before (left) and after (right) removal of the cell cycle effect in the Th2 data set. Each point represents a cell, coloured according to the empirically assigned cell cycle phase. Bars represent the location of cells on each axis."}
corrected <- removeBatchEffect(exprs(sce), batch=hard.assign)
assayDataElement(sce, "corrected") <- corrected
pca1 <- plotPCA(sce, colour_by="assignments") + fontsize + ggtitle("Before removal")
pca2 <- plotPCA(sce, exprs_values="corrected", colour_by="assignments") + 
    fontsize + ggtitle("After removal")
multiplot(pca1, pca2, cols=2)
```

For other analyses (e.g., detecting DEGs or HVGs), the phase-corrected values from `removeBatchEffect` should not be used directly.
Rather, an equivalent result can be obtained by blocking on the assigned phase in the design matrix.
The additional model coefficients will absorb any phase-related effects on expression such that they will not affect estimation of the effects of other experimental factors.
Note that users should ensure that the phase is not confounded with other factors of interest.
For example, model fitting is not possible if all cells in one experimental condition are in one phase, and all cells in another condition are in a different phase.

```{r}
design <- model.matrix(~ factor(hard.assign))
```

## Detecting DEGs between pre-defined groups of cells

# Conclusions

# Software availability

```{r}
sessionInfo()
```

# Author contributions

A.T.L.L. developed the workflow on all data sets.

# Competing interests

No competing interests were disclosed.

# Grant information

CRUK core funding (SW73) to J.C.M.

# Acknowledgements

Aaron is pretty awesome.

# References

