---
title: A worfklow for low-level analyses of single-cell RNA-seq data
author: 
    - name: Aaron T. L. Lun
      affiliation: Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom
    - name: John C. Marioni
      affiliation: Cancer Research UK Cambridge Institute, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, United Kingdom; EMBL European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, United Kingdom
date: 19 February 2016
vignette: >
    %\VignetteIndexEntry{A worfklow for low-level analyses of single-cell RNA-seq data}
    %\VignetteEngine{knitr::rmarkdown}
output: 
    BiocStyle::html_document:
        fig_caption: yes
bibliography: ref.bib
---

```{r style, echo=FALSE, results='hide', message=FALSE}
library(BiocStyle)
library(knitr)
opts_chunk$set(error=FALSE)
opts_chunk$set(fig.width=7, fig.height=7)
opts_chunk$set(dpi=300, dev="png", dev.args=list(pointsize=15))
options(bitmapType="cairo")
```

```{r, message=FALSE, echo=FALSE, results='hide'}
library(DESeq2)
library(scran)
library(edgeR)
library(scater)
library(gplots)
library(gdata)
library(R.utils)
library(org.Mm.eg.db)
```

# Introduction

Single-cell RNA sequencing (scRNA-seq) is widely used to measure the genome-wide expression profile of individual cells.
From each cell, mRNA is isolated and reverse transcribed to cDNA for high-throughput sequencing [@stegle2015computational].
This can be done using microfluidics platforms like the Fluidigm C1 [@pollen2014lowcoverage], or with protocols based on microtiter plates like Smart-seq2 [@picelli2014fulllength].
The number of reads mapped to each gene can then be used to quantify its expression in each cell.
Alternatively, unique molecular identifiers (UMIs) can be used to directly measure the number of transcript molecules for each gene [@islam2014quantitative].
Count data can be analyzed via dimensionality reduction and clustering to identify new cell subpopulations, and to detect highly variable genes (HVGs) or differentially expressed genes (DEGs) between subpopulations or conditions.
This provides biological insights at a single-cell resolution that cannot be attained with conventional bulk RNA sequencing of cell populations.

Strategies for scRNA-seq data analysis differ markedly from those for bulk RNA-seq.
One technical reason is that scRNA-seq data is much noisier than bulk data [@brennecke2013accounting;@marinov2014singlecell].
Reliable capture (i.e., conversion) of transcripts into cDNA for sequencing is difficult with the low quantity of RNA in a single cell.
This increases the high frequency of drop-out events where none of the transcripts for a gene are captured.
More PCR amplification cycles are often used to compensate for low input quantities, but this can lead to amplification biases and inflated measures of transcript levels.
Dedicated analysis steps are required to deal with this noise, especially during quality control.
In addition, scRNA-seq data can be used to study cell-to-cell heterogeneity, e.g., to identify new cell subtypes, to characterize differentiation processes, to separate cells based on cell cycle phase, or to identify HVGs driving variability across the population [@vallejos2015basics;@fan2016characterizing;@trapnell2014dynamics].
This is simply not possible with bulk data, such that custom methods are required to perform these analyses. 

This article describes a computational workflow for basic analysis of scRNA-seq data using software packages from the open-source Bioconductor project [@huber2015orchestrating].
Starting from a count matrix, this workflow contains the steps required for quality control to remove problematic cells; normalization of cell-specific biases, with and without spike-ins; cell-cycle phase classification from gene expression data; data exploration to identify putative subpopulations; and finally, HVG and DEG identification to prioritize interesting genes.
The application of different steps in the workflow will be demonstrated on several public scRNA-seq data sets -- one from a study of cell types in the mouse brain, and another from a study of mouse embryonic stem cells (mESCs) cultured under different conditions [@kold2015singlecell].
The aim is to provide a variety of modular usage examples that can be applied to construct custom analysis pipelines.

# A simple analysis on haematopoietic stem cells

## Overview

To introduce most of the concepts of scRNA-seq data analysis, we use a relatively simple data set from a study of haematopoietic stem cells (HSCs) [@wilson2015combined].
Single mouse HSCs were isolated into microtiter plates and libraries were prepared for 96 cells using the Smart-seq2 protocol.
A constant amount of spike-in RNA from the External RNA Controls Consortium (ERCC) was also added to each cell prior to library preparation.
High-throughput sequencing was performed and the expression of each gene was quantified by counting the total number of reads mapped to its exonic regions.
Similarly, the quantity of each spike-in transcript was measured by counting reads mapped to the spike-in reference sequence.
Counts for all genes/transcripts in each cell were obtained from the NCBI Gene Expression Omnibus (GEO) as a supplementary file under the accession number GSE61533.

For simplicity, we forgo a description of the read processing steps required to generate the count matrix, i.e., read alignment and counting into features.
These steps have been described in some detail elsewhere [@love2015rnaseq], and are largely the same for bulk and single-cell data.
The only additional consideration is that the spike-in information must be included in the pipeline.
Typically, spike-in sequences can be included as additional FASTA files during genome index building prior to alignment, while genomic intervals for both spike-in transcripts and endogenous genes can be concatenated into a single GTF file prior to counting.
For users favouring a R-based approach to read alignment and counting, we suggest using the methods in the `r Biocpkg("Rsubread")` package [@liao2013subread;@liao2014featurecounts].

## Count loading and quality control

The first task is to load the count matrix into memory.
This requires some work to decompress and retreive the data from the Excel format.
Each row of the matrix represents an endogenous gene or a spike-in transcript, and each column represents a single HSC.
For convenience, the counts for spike-in transcripts and endogenous genes are stored in a `SCESet` object from the `r Biocpkg("scater")` package.

```{r}
library(R.utils)
gunzip("GSE61533_HTSEQ_count_results.xls.gz", remove=FALSE, overwrite=TRUE)
library(gdata)
all.counts <- read.xls('GSE61533_HTSEQ_count_results.xls', sheet=1, header=TRUE, row.names=1)
library(scater)
sce <- newSCESet(countData=all.counts)
dim(sce)
```

We annotate those rows corresponding to ERCC spike-ins and mitochondrial genes.
This information can be easily extracted from the row names, though in general, identifying mitochondrial genes from standard identifiers like Ensembl requires access to extra annotation (this will be discussed later in more detail).
We then calculate quality control metrics such as the total number of counts, the proportion of counts for the mitochondrial genes or spike-in transcripts, etc.
These metrics are stored in the `pData` of the `SCESet` for future reference.

```{r}
is.spike <- grepl("^ERCC", rownames(sce))
fData(sce)$is_feature_spike <- is.spike
is.mito <- grepl("^mt-", rownames(sce))
sce <- calculateQCMetrics(sce, feature_controls=list(Spike=is.spike, Mt=is.mito))
head(colnames(pData(sce)))
```

Low-quality cells are defined as those where the endogenous RNA has not been efficiently captured (i.e., converted into cDNA and amplified) during library preparation.
These can be identified as those cells with a low sum of counts for the endogenous genes.
In general, any cell with a count sum that is an order of magnitude lower than the median across all cells can be considered to be of low quality and removed.
A more relaxed threshold may need to be used when strong heterogeneity in total RNA content is expected across cells.

```{r}
endo.sum <- sce$counts_endogenous_features
summary(endo.sum)
keep <- endo.sum >= median(endo.sum)/10
sce <- sce[,keep]
sum(!keep)
```

Cells with very few expressed (i.e., non-zero) counts are also removed.
This ensures that the total count in each cell is not driven by a small number of transcripts.
Cells with fewer than 1000 expressed genes are considered to be of poor quality, as it suggests that the diverse transcript population has not been successfully captured.
Here, all cells have a reasonable number of expressed genes and so no removal is performed.

```{r}
summary(sce$total_features)
```

Another measure of quality is the proportion of reads mapped to genes in the mitochondrial genome.
High proportions are indicative of poor-quality cells [@islam2014quantitative;@ilicic2016classification], possibly because of increased apoptosis and/or loss of cytoplasmic RNA from lysed cells.
Defining a threshold on the proportion is not straightforward as it depends largely on the cell type and the experimental protocol.
If we assume that most cells in the data set are not apoptotic, then the threshold can be set to remove any large outliers from the distribution of proportions.
Here, no obvious outliers are present, so no removal will be performed.
A similar case can be made for the proportion of reads mapped to spike-in transcripts.

```{r controlplothsc, fig.width=12, fig.height=6, fig.cap="Histogram of the proportion of reads mapped to mitochondrial genes (left) or spike-in transcripts (right) across all remaining cells in the HSC data set."}
par(mfrow=c(1,2))
mito.props <- sce$pct_counts_feature_controls_Mt
hist(mito.props, xlab="Mitochondrial proportion (%)", ylab="Number of cells", 
    breaks=20, cex.lab=1.4, cex.axis=1.2, main="")
spike.props <- sce$pct_counts_feature_controls_Spike
hist(spike.props, xlab="ERCC proportion (%)", ylab="Number of cells", 
    breaks=20, cex.lab=1.4, cex.axis=1.2, main="")
```

An alternative approach to quality control is to perform a principal components analysis (PCA) based on the quality metrics for each cell, e.g., the total number of reads, the total number of features, the proportion of mitochondrial or spike-in reads.
Outliers on a PCA plot may be indicative of low-quality cells that have aberrant technical properties compared to the (presumed) majority of high-quality cells.

```{r pcaqualplothsc, fig.cap="PCA plot for all remaining cells in the HSC data set, constructed using quality metrics. The first and second components are shown on each axis, along with the percentage of total variance explained by each component. Bars represent the coordinates of the cells on each axis."}
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
plotPCA(sce, pca_data_input = "pdata", detect_outliers=TRUE) + fontsize
```

In this case, two cells are identified as outliers from the PCA plot.
These cells can be removed from the data set, under the assumption that they represent low-quality samples.

```{r}
alt.sce <- plotPCA(sce, pca_data_input = "pdata", detect_outliers=TRUE, 
    draw_plot=FALSE, return_SCESet=TRUE)
alt.sce <- alt.sce[,!alt.sce$outlier]
```

Methods like outlier detection and support vector machines can provide greater power to distinguish low-quality cells from high-quality counterparts [@ilicic2016classification].
This is because they are able to detect subtle patterns across many quality metrics simultaneously. 
However, this comes at some cost to interpretability, as the reason for removing a given cell may not always be obvious.
Thus, for this workflow, we will use the simple approach whereby each quality metric is considered separately.

## Filtering out low-abundance genes

Low-abundance genes are removed as the counts are too low for reliable statistical inferences.
In addition, the discreteness of the counts may interfere with downstream statistical procedures, e.g., by compromising the accuracy of asymptotic approximations.
Here, low-abundance genes are defined as those with an average count across cells below 1.
Removing them avoids problems with discreteness and also reduces the amount of computational work.

```{r}
keep <- rowMeans(counts(sce)) >= 1
sce <- sce[keep,] 
sum(keep)
```

An alternative approach to gene filtering is to select genes that have non-zero counts in at least _n_ cells. 
This provides some more protection against outlier expression patterns, i.e., genes with strong expression in only one or two cells. 
Such outlier patterns are typically uninteresting unless rare cells are of particular interest.
An example of this approach is shown below for _n_ set to 10.

```{r}
alt.keep <- rowSums(is_exprs(sce)) >= 10
sum(alt.keep)
```

The relationship between the proportion of expressing cells and the mean can be examined more closely in the plot below.
The two statistics tend to be well-correlated, so filtering on either should give similar results.

```{r geneplothsc, fig.cap="Frequency of expression against the mean expression for each gene. Circles represent endogenous genes and triangles represent spike-in transcripts or mitochondrial genes. The bars on each axis represent the location of each gene on that axis. Genes above high technical dropout are defined as those above a non-linear trend fitted to the triangles."}
plotQC(sce, type = "exprs") + fontsize
```

In general, we prefer the mean-based filter as it tends to be less aggressive.
A gene will be retained as long as it has sufficient expression in any subset of cells.
The "at least _n_" filter depends heavily on the choice of _n_ -- in this case, a gene expressed in a subset of 9 cells would be lost.
While the mean-based filter will retain more outlier-driven genes, this can be handled downstream by choosing methods that are robust to outliers.

## Normalization of cell-specific biases

Read counts are subject to differences in capture efficiency and sequencing depth between cells [@stegle2015computational].
Normalization is required to eliminate these cell-specific biases prior to downstream quantitative analyses.
This is often done by assuming that most genes are not differentially expressed (DE) between cells.
Any systematic difference in count size across the non-DE majority of genes between two cells is assumed to represent bias and is removed by scaling.
More specifically, "size factors" are calculated that represent the extent to which counts should be scaled in each library.

Size factors can be computed with several different approaches, e.g., using the `estimateSizeFactorsFromMatrix` function in the `r Biocpkg("DESeq2")` package [@anders2010differential;@love2014moderated], or with the `calcNormFactors` function [@robinson2010scaling] in the `r Biocpkg("edgeR")` package (this requires an additional multiplication by the library size).
However, single-cell data can be problematic for these bulk data-based methods due to the dominance of low and zero counts.
To overcome this, we pool counts from many cells to increase the count size for accurate size factor estimation [@lun2016much].
Pool-based size factors are then "deconvolved" into cell-based factors for cell-specific normalization.

```{r, warning=FALSE}
sce$size.factor <- normalizeBySums(sce, sizes=c(20, 40, 60, 80))
summary(sce$size.factor)
```

In this case, the size factors are tightly correlated with the total counts for all cells.
This suggests that the systematic differences between cells are primarily driven by differences in capture efficiency or sequencing depth.
Any DE between cells would yield a non-linear trend between the total count and size factor, and/or increased scatter around the trend.
This does not occur here as strong DE is unlikely to exist between cells of the same type.

```{r normplothsc, fig.cap="Size factors from deconvolution, shown against the total counts for all cells in the HSC data set. Axes are shown on a log-scale."}
plot(sce$size.factor, sce$total_counts/1e6, log="xy", cex.axis=1.2, cex.lab=1.4,
    ylab="Total count (per million)", xlab="Size factor", main="")
```

Normalized log-expression values can be computed for use in downstream analyses.
Each value is defined as the log-ratio of each count to the size factor for the corresponding cell (after adding a small prior count to avoid undefined values at zero counts).
Division by the size factor ensures that any cell-specific biases are removed.
The log-transformation is also useful as larger counts can be modelled reasonably well with a log-normal distribution [@law2014voom].
The computed values are stored as an `"exprs"` matrix in addition to the other assay elements.

```{r}
sce <- normalize(sce)
```

## Data exploration with dimensionality reduction techniques

Dimensionality reduction is often useful to examine major features of the data before more quantitative analyses.
Of particular interest is whether the HSCs partition into distinct subpopulations.
This can be visualized by constructing a PCA plot from the normalized log-expression values.
Cells with similar expression profiles should be located close together on the plot.

```{r pcaplothsc, fig.cap="PCA plot constructed from normalized log-expression values, where each point represents a cell in the HSC data set. First and second components are shown, along with the percentage of variance explained. Bars represent the coordinates of the cells on each axis. None of the cells are controls (e.g., empty wells) so the legend can be ignored."}
plotPCA(sce, exprs_values="exprs") + fontsize
```

Alternatively, the PCA plot can be constructed from a matrix of correlations between cells. 
Two cells with similar expression profiles will exhibit similar patterns of correlations to other cells.
As a result, those two cells will be closer together in the plot.
This approach tends to be more robust to noise and outliers that would dominate a standard PCA plot, at the cost of being less sensitive to differences in the expression profiles.

```{r pcacorplothsc, fig.cap="PCA plot constructed from a matrix of Spearman rank correlations between cells, where each point represents a cell in the HSC data set."}
cor.mat <- cor(assayDataElement(sce, "exprs"), method="spearman")
out <- prcomp(cor.mat)
plot(out$x[,1], out$x[,2], xlab="PC1", ylab="PC2", pch=16, cex.axis=1.2, cex.lab=1.4)
```

Another popular approach to dimensionality reduction is the _t_-stochastic neighbour embedding (_t_-SNE) method [@van2008visualizing].
_t_-SNE tends to work better than PCA for large data sets with complex substructure, at the cost of more computational effort and complexity.
Unlike PCA, _t_-SNE is a stochastic method -- users should run the algorithm several times to ensure that the results are representative, and then set a seed to ensure that the chosen results are reproducible.
It is also advisable to test different settings of the "perplexity" parameter as this will affect the distribution of points in the low-dimensional space.

```{r tsneplothsc, fig.cap="_t_-SNE plot constructed from normalized log-expression values using a range of perplexity values. In each plot, each point represents a cell in the HSC data set. Bars represent the coordinates of the cells on each axis.", fig.width=12, fig.height=6}
set.seed(100)
out5 <- plotTSNE(sce, exprs_values="exprs", perplexity=5) + fontsize + ggtitle("Perplexity = 5")
out10 <- plotTSNE(sce, exprs_values="exprs", perplexity=10) + fontsize + ggtitle("Perplexity = 10")
out20 <- plotTSNE(sce, exprs_values="exprs", perplexity=20) + fontsize + ggtitle("Perplexity = 20")
multiplot(out5, out10, out20, cols=3)
```

By default, both the `plotPCA` and `plotTSNE` functions will only use the top 500 genes with the highest variances.
This focuses on the genes that are driving heterogeneity in the population and should provide greater visual resolution of any systematic differences between groups of cells.
For this data set, all methods suggest that there is no separation into distinct subpopulations.
This is consistent with a homogenous population of cells of the same type.
Of course, there are many dimensionality reduction techniques that we have not considered here but could also be used, e.g., multidimensional scaling.

## Classification of cell cycle phase 

We use the prediction method described by @scialdone2015computational to classify cells into cell cycle phases based on the gene expression data.
Using a training data set, the sign of the difference in expression between two genes was computed for each pair of genes.
Pairs were chosen with changes in the sign across cell cycle phases.
Cells in a test data set can then be classified into the appropriate phase, based on whether the observed sign is consistent with one phase or another.
This is achieved using the `cyclone` function on a pre-trained set of gene pairs for mouse data.
(Some additional work is necessary to match the gene symbols in the data to the Ensembl annotation in the set of pairs.)

```{r phaseplothsc, message=FALSE, fig.cap="Cell cycle phase scores from applying the pair-based classifier on the HSC data set, where each point represents a cell."}
mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran"))
library(org.Mm.eg.db)
anno <- select(org.Mm.eg.db, keys=rownames(sce), keytype="SYMBOL", column="ENSEMBL")
ensembl <- anno$ENSEMBL[match(rownames(sce), anno$SYMBOL)]
keep <- !is.na(ensembl)
assignments <- cyclone(sce[keep,], mm.pairs, gene.names=ensembl[keep])
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score",
    pch=16, cex.axis=1.2, cex.lab=1.4, main="")
```

Cells are classified as being in G1 phase if the G1 score is above 0.5; in G2/M phase if the G2/M score is above 0.5; and in S phase, if neither is above 0.5.
Here, the vast majority of cells are classified as being in G1 phase.
We will focus on these cells for the downstream analysis.
Cells in other phases are removed to avoid potential confounding effects from cell cycle-induced differences.
Alternatively, if a non-negligible number of cells are in other phases, we can use the assigned phase as a blocking factor in downstream analyses.
This protects against cell cycle effects without discarding a substantial amount of information.

```{r}
g1.only <- assignments$score$G1 > 0.5
sce <- sce[,g1.only]
```

Pre-trained classifiers are available in `r Rpackage("scran")` for human and mouse experiments.
These tend to work reasonably well -- the classifier is non-parametric with few assumptions, and the transcriptional program associated with cell cycling should be mostly conserved across different cell types and biological settings.
However, users can construct a custom classifier from their own training data using the `sandbag` function.
This may be necessary for other model organisms where pre-trained classifiers are not available.

## Identifying HVGs from the normalized log-expression 

We identify HVGs to focus on the genes that are driving heterogeneity across the population of cells.
This requires estimation of the variance in expression for each gene, followed by decomposition of the variance into biological and technical components.
HVGs are then identified as those genes with the highest biological components.
This avoids prioritizing genes that are highly variable due to technical factors such as sampling noise during RNA capture and library preparation.

Ideally, the technical component would be estimated by fitting a mean-variance trend to the spike-in transcripts.
Recall that the same set of spike-ins is added in the same quantity to each cell.
This means that the spike-in transcripts should exhibit no biological variability.
Thus, any variance in the counts of each spike-in transcript should be technical in origin.
Fitting is performed by the `trendVar` function, using a loess curve with a low span as the trend is highly non-linear.
(Some adjustment of the parameters may be required to obtain a satisfactory fit.)

```{r}
var.fit <- trendVar(sce, trend="loess", span=0.3)
```

Given the mean abundance of a gene, the fitted value of the trend can be used as an estimate of the technical component for that gene.
The biological component of the variance can then be estimated by subtracting the technical component from the total variance of each gene in the `decomposeVar` function.

```{r}
var.out <- decomposeVar(sce, var.fit)
```

<!--
In practice, this approach is complicated by the difficulty of accurately fitting a complex trend to a few spike-in points.
An alternative is to fit the mean-variance trend to the endogenous genes.
This assumes that the majority of genes are constantly expressed, such that the technical component dominates the total variance of expression for those genes.
The fitted value of the trend can then be used as an estimate of the technical component.
This exploits the presence of the larger number of endogenous genes to obtain a more stable fit.

```{r}
var.fit2 <- trendVar(sce, trend="loess", use.spikes=FALSE)
var.out2 <- decomposeVar(sce, var.fit2, get.spikes=TRUE)
```
-->

In practice, this approach is complicated by the difficulty of accurately fitting a complex trend to a low number of unevenly distributed points.
We assess the suitability of the fitted trend by examining whether it is consistent with the spike-in variances. 
The former generally passes through the bulk of the latter in the plot below, though some inaccuracy is unavoidable for mean intervals containing few spike-in transcripts.

<!--
This result suggests that the assumption is valid in this data set, i.e., most endogenous genes exhibit technical variance with little biological heterogeneity.
However, if the trend were systematically greater than the spike-in variances, the assumption would not hold.
We would then have to rely on a (potentially unstable) trend fitted to the spike-in variances only.
-->

```{r hvgplothsc, fig.cap="Variance of normalized log-expression values for each gene in the HSC data set, plotted against the mean log-expression. The red line represents the mean-dependent trend in the technical variance of the spike-in transcripts (also highlighted as red points)."}
plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab="Mean log-expression", 
    ylab="Variance of log-expression")
points(var.fit$mean, var.fit$var, col="red", pch=16)
o <- order(var.out$mean)
lines(var.out$mean[o], var.out$tech[o], col="red", lwd=2)
```

The top HVGs are identified by ranking genes on their biological components.
This can be used to prioritize interesting genes for further investigation.

```{r}
top.hvgs <- order(var.out$bio, decreasing=TRUE)
write.table(file="hsc_hvg.tsv", var.out[top.hvgs,], sep="\t", quote=FALSE, col.names=NA)
head(var.out[top.hvgs,])
```

Of course, there are many ways of defining HVGs, e.g., by using the coefficient of variation [@kolod2015singlecell;@kim2015characterizing], through the dispersion parameter in the negative binomial distribution [@mccarthy2012differential], or as a proportion of total variability [@vallejos2015basics].
We use the variance of the log-expression values because the log-transformation provides some protection against genes with strong expression in only one or two outlier cells.
This ensures that the set of top HVGs is not dominated by genes with (mostly uninteresting) outlier expression patterns.
However, the cost of this robustness is the need to fit a complex mean-variance relationship.

## Identifying correlated gene pairs with Spearman's rho

Another useful procedure is to identify the HVGs that are highly correlated with one another.
This distinguishes between HVGs caused by random noise and those involved in driving systematic differences between subpopulations.
Gene pairs with significantly large positive or negative values for Spearman's rho are identified using the `correlatePairs` function.
Note that we only apply this function for the top set of HVGs -- doing so for all possible gene pairs would require too much computational time and may prioritize uninteresting genes that have strong correlations but low variance, e.g., tightly co-regulated house-keeping genes.

```{r}
set.seed(100)
var.cor <- correlatePairs(sce[top.hvgs[1:200],])
write.table(file="hsc_cor.tsv", var.cor, sep="\t", quote=FALSE, col.names=NA)
head(var.cor)
```

The top set of correlated HVGs can be prioritized for follow-up studies.
For example, a set of correlated genes can be used as markers to validate the existence of a subpopulation of cells with a specific expression pattern, e.g., via fluorescence-activated cell sorting, immunohistology or RNA flourescence _in situ_ hybridization.
Negatively correlated pairs may be particularly useful in this respect, as they provide a clear "negative control" signal for cells outside of the subpopulation.

Larger sets of correlated genes can be assembled by treating genes as nodes in a graph and each pair of genes with significantly large correlations as an edge.
In this manner, an undirected graph can be constructed using methods in the `r Biocpkg("RBGL")` package.
Highly connected subgraphs can then be identified and defined as gene sets.
This provides a convenient summary of the pairwise correlations between genes.

```{r, message=FALSE}
library(RBGL)
sig.cor <- var.cor$FDR <= 0.05
g <- ftM2graphNEL(cbind(var.cor$gene1, var.cor$gene2)[sig.cor,], W=NULL, V=NULL, edgemode="undirected")
cl <- highlyConnSG(g)$clusters
cl <- cl[order(lengths(cl), decreasing=TRUE)]
cl <- cl[lengths(cl) > 2]
cl
```

## Using correlated HVGs for further data exploration

For further analyses, we focus on the significantly correlated HVGs for which any substructure should be most pronounced.
This may allow us to identify subpopulations that would have otherwise been masked by random noise in the expression profiles..

```{r}
chosen <- unique(c(var.cor$gene1[sig.cor], var.cor$gene2[sig.cor]))
norm.exprs <- exprs(sce)[chosen,,drop=FALSE]
```

We construct a simple dendrogram to group together cells with similar expression patterns across the chosen genes.
Here, we cluster on Euclidean distances to provide greater sensitivity for low numbers of genes.
Ward's clustering criterion is used to minimize the total variance within each cluster.

```{r}
my.dist <- dist(t(norm.exprs))
my.tree <- hclust(my.dist, method="ward.D2")
```

In addition, subpopulations of cells can be explicitly defined from the dendrogram..
A dynamic tree cut is performed to define the clusters, using the `cutreeDynamic` function in the `r CRANpkg("dynamicTreeCut")` package [@langfelder2008defining].
Note that some tuning of `cutHeight` is required to obtain satisfactory results for each data set.

```{r}
library(dynamicTreeCut)
my.clusters <- unname(cutreeDynamic(my.tree, distM=as.matrix(my.dist), 
    verbose=0, cutHeight=60))
my.clusters
```

We can visualize this dendrogram result with a heatmap.
All expression values are mean-centred for each gene to highlight the relative expression between cells.
We recommend storing the heatmap at a sufficiently high resolution so that the relevant genes can be easily identified for further examination.

```{r heatmaphsc, message=FALSE, fig.width=7, fig.height=10, fig.cap="Heatmap of mean-centred normalized log-expression values for correlated HVGs in the HSC data set. Dendrograms are formed by hierarchical clustering on the Euclidean distances between genes (row) or cells (column). Column colours represent the cluster to which each cell is assigned after a dynamic tree cut."}
library(gplots)
heat.vals <- norm.exprs - rowMeans(norm.exprs)
heatmap.2(heat.vals[chosen,], col=bluered, symbreak=TRUE, trace='none', cexRow=0.8,
    ColSideColors=c("darkgreen", "orange", "dodgerblue")[my.clusters+1],
    Colv=as.dendrogram(my.tree))
```

A close look suggests that a _H2-Aa_/_Cd74_-expressing subpopulation exists alongside a _Fos_/_Jun_-negative subpopulation.
_H2-Aa_ codes for a component of the class II major histocompatibility complex and may be indicative of B-cell contamination [@heng2008immunological].
_Fos_ and _Jun_ may also be relevant as they are involved in cell proliferation [@angel1991role].
In addition, these visual subpopulations roughly correspond to the computationally identified clusters from the dynamic tree cut.
Further analyses can then be performed on those empirical clusters -- for example, we can perform a DE analysis to identify marker genes for each corresponding subpopulation (this will be explored in more detail later).

That being said, users should treat clustering results with some caution.
It is difficult to maintain statistical rigour during clustering to protect against the formation of spurious clusters.
As such, determining whether a cluster is "real" or not usually depends on subjective judgement, unless the clusters are very clearly defined (e.g., strong separation on a PCA plot, widespread differences in the expression profiles).
Moreover, different algorithms can yield substantially different clusters by focusing on different aspects of the data.
In short, experimental validation of the clustering results is critical to ensure that the putative subpopulations actually exist.

Finally, dimensionality reduction can be applied using only the set of HVGs to highlight any substructure that might be present.
This is shown below for both PCA and _t_-SNE plots, though in this case, focusing on HVGs does not provide any additional separation into distinct subpopulations.

```{r pcareduxhsc, fig.width=10, fig.height=6, fig.cap="PCA (left) and _t_-SNE plots (right) using only the expression values for significantly correlated HVGs in the HSC data set. Each cell is represented by a point in each plot, and the bars represent the cell coordinates on each axis."}
set.seed(100)
out.pca <- plotPCA(sce, exprs_values="exprs", feature_set=chosen) + fontsize
out.tsne <- plotTSNE(sce, exprs_values="exprs", feature_set=chosen) + fontsize
multiplot(out.pca, out.tsne, cols=2)
```

# A more complex analysis on brain cell types

## Overview

We proceed to tackle a more complex data set from a study of cell types in the mouse brain [@zeisel2015brain].
This contains approximately 3000 cells of varying types such as oligodendrocytes, microglia and neurons.
Individual cells were isolated using the Fluidigm C1 microfluidics system and library preparation was performed on each cell using a UMI-based protocol.
After sequencing, expression was quantified by counting the number of UMIs mapped to each gene.
Count data for all endogenous genes, mitochondrial genes and spike-in transcripts were obtained from http://linnarssonlab.org/cortex.

## Count loading 

The count data are distributed across several files, so some work is necessary to consolidate them into a single matrix.
We define a simple utility function for loading data in from each file. 
(We stress that this function is only relevant to the current data set, and should _not_ be used for other data sets.
In general, this kind of effort is not required if the counts are in a single file and separated from the metadata.)

```{r}
readFormat <- function(infile) { 
    # First column is empty.
    metadata <- read.delim(infile, stringsAsFactors=FALSE, header=FALSE, nrow=10)[,-1] 
    rownames(metadata) <- metadata[,1]
    metadata <- metadata[,-1]
    metadata <- as.data.frame(t(metadata))
    # First column after row names is some useless filler.
    counts <- read.delim(infile, stringsAsFactors=FALSE, header=FALSE, row.names=1, skip=11)[,-1] 
    counts <- as.matrix(counts)
    return(list(metadata=metadata, counts=counts))
}
```

Using this function, we read in the counts for the endogenous genes, ERCC spike-ins and mitochondrial genes.

```{r}
endo.data <- readFormat("expression_mRNA_17-Aug-2014.txt")
spike.data <- readFormat("expression_spikes_17-Aug-2014.txt")
mito.data <- readFormat("expression_mito_17-Aug-2014.txt")
```

We also need to rearrange the columns for the mitochondrial data, as the order is not consistent with the other files.

```{r}
m <- match(endo.data$metadata$cell_id, mito.data$metadata$cell_id)
mito.data$metadata <- mito.data$metadata[m,]
mito.data$counts <- mito.data$counts[,m]
```

```{r, echo=FALSE}
stopifnot(identical(endo.data$metadata$cell_id, spike.data$metadata$cell_id)) # should be the same.
stopifnot(all(endo.data$metadata$cell_id==mito.data$metadata$cell_id)) # should now be the same.
```

The counts are then combined into a single matrix for constructing a `SCESet` object.
For convenience, metadata for all cells are stored in the same object for later access.

```{r}
all.counts <- rbind(endo.data$counts, mito.data$counts, spike.data$counts)
metadata <- AnnotatedDataFrame(endo.data$metadata)
sce <- newSCESet(countData=all.counts, phenoData=metadata)
dim(sce)
```

We also add annotation identifying which rows correspond to each class of features.

```{r}
nrows <- c(nrow(endo.data$counts), nrow(mito.data$counts), nrow(spike.data$counts))
is.spike <- rep(c(FALSE, TRUE, FALSE), nrows)
fData(sce)$is_feature_spike <- is.spike
is.mito <- rep(c(FALSE, FALSE, TRUE), nrows)
```

```{r, echo=FALSE, results='hide'}
# Save some memory.
rm(mito.data, endo.data, spike.data)
gc()
```

## Quality control on the cells and genes

The original authors of the study have already removed low-quality cells prior to data publication.
Nonetheless, we can compute some metrics to check that whether the remaining cells are satisfactory.

```{r}
sce <- calculateQCMetrics(sce, feature_controls=list(Spike=is.spike, Mt=is.mito)) 
```

As previously described, we remove cells with low total counts for endogenous genes or with few total expressed features.

```{r}
endo.sum <- sce$counts_endogenous_features 
count.keep <- endo.sum >= median(endo.sum)/10
sum(!count.keep)
feature.keep <- sce$total_features >= 1000
sum(!feature.keep)
```

We also examine the distribution of the proportions of total reads mapped to mitochondrial or spike-in genes.

```{r controlplotbrain, fig.width=12, fig.height=6, fig.cap="Histogram of the proportion of reads mapped to mitochondrial genes (left) or spike-in transcripts (right) across all cells in the brain data set."}
par(mfrow=c(1,2))
mito.props <- sce$pct_counts_feature_controls_Mt
hist(mito.props, xlab="Mitochondrial proportion (%)", ylab="Number of cells", 
    breaks=20, cex.lab=1.4, cex.axis=1.2, main="")
spike.props <- sce$pct_counts_feature_controls_Spike
hist(spike.props, xlab="ERCC proportion (%)", ylab="Number of cells", 
breaks=20, cex.lab=1.4, cex.axis=1.2, main="")
```

Here, a couple of clear outliers are observed for the spike-in proportions.
We remove cells with proportions above a threshold of 15%, as this is where the probability density of the empirical distribution becomes negligible.
For the mitochondrial proportions, the distinction is more difficult.
This may be because of the presence of many cell types with different mitochondria copy number or activity.
In this data set, we set a threshold of 70% and remove the most extreme cases on the right tail.

```{r}
spike.keep <- spike.props <= 15
sum(!spike.keep)
mito.keep <- mito.props <= 70
sum(!mito.keep)
```

Removal of low-quality cells can then be performed by combining all of the metrics.
The vast majority of cells are retained, which suggests that the original quality control procedures were generally adequate.

```{r}
total.keep <- count.keep & feature.keep & spike.keep & mito.keep
sce <- sce[,total.keep]
sum(total.keep)
```

Low-abundance genes are also removed by applying a simple mean-based filter.
This yields fewer genes than in the HSC data set, mostly because the sequencing depth per cell is much lower.

```{r}
keep <- rowMeans(counts(sce)) >= 1
sce <- sce[keep,]
sum(keep)
```

## Normalization and cell-cycle classification

Normalization of cell-specific biases is performed using the `normalizeBySums` function.
Here, we cluster similar cells together and normalize the cells in each cluster using the deconvolution method.
This improves the accuracy of normalization by reducing the number of DE genes between cells in the same cluster.
Normalization between clusters is then performed to ensure that expression values from cells in different clusters are comparable.

```{r}
clusters <- quickCluster(sce)
sce$size.factor <- normalizeBySums(sce, cluster=clusters)
sce <- normalize(sce)
```

Greater scatter is observed between the total count for each cell and its size factor.
This is consistent with an increased amount of DE between cells of different types, which compromises the accuracy of library size normalization [@robinson2010scaling].
In contrast, the size factors are estimated based on median ratios and are more robust to the presence of DE between cells.

```{r normplotbrain, fig.cap="Size factors from deconvolution, shown against the total counts for all cells in the brain data set. Axes are shown on a log-scale."}
plot(sce$size.factor, sce$total_counts/1e6, log="xy", cex.axis=1.2, cex.lab=1.4,
    ylab="Total count (per million)", xlab="Size factor", main="")
```

We also attempt to classify cells into cell cycle phases using the `cyclone` method.
We use additional cores to speed up classification for data sets with many cells.
However, examination of the plot below indicates that many of the G1 and G2/M scores are ambiguous.
This highlights the potential difficulties of training a classifier on one cell type (mouse embryonic stem cells -- see @scialdone2015computational for more details) and applying it on a substantially different cell type.
Some neuron types are particularly problematic as they are postmitotic and do not belong in any phase of the cell cycle.

```{r, echo=FALSE, results='hide', message=FALSE}
mm.pairs <- readRDS(system.file("exdata", "mouse_cycle_markers.rds", package="scran"))
library(org.Mm.eg.db)
```

```{r phaseplotbrain, message=FALSE, fig.cap="Cell cycle phase scores from applying the pair-based classifier on the brain data set, where each point represents a cell."}
anno <- select(org.Mm.eg.db, keys=rownames(sce), keytype="SYMBOL", column="ENSEMBL")
ensembl <- anno$ENSEMBL[match(rownames(sce), anno$SYMBOL)]
keep <- !is.na(ensembl)
assignments <- cyclone(sce[keep,], mm.pairs, gene.names=ensembl[keep], 
    BPPARAM=MulticoreParam(5))
plot(assignments$score$G1, assignments$score$G2M, xlab="G1 score", ylab="G2/M score",
    pch=16, cex.axis=1.2, cex.lab=1.4, main="")
```

Given the lack of definitive classification, we will not perform any processing of the data set by cell cycle phase.
However, this information is still useful for verifying downstream results.
For example, if putative subpopulations have distinctly different phase scores, we may suspect that the differences between subpopulations are being driven by cell cycle effects.

## Data exploration to examine the effect of technical factors

For large experiments, data exploration has two functions -- to identify interesting biology, and also to check the effect of various technical factors.
PCA plots constructed from the expression data suggest that distinct subpopulations are present.
Some of the substructure may be due to differences in the tissue from which the cells were extracted, e.g.,
    cells from the cortex and hippocampus dominate the bottom-right and bottom-left corners of the plot, respectively.
In contrast, cells taken from mice of different sexes mix throughout the plot, indicating that sex has little effect on the overall differences across the data set.

```{r, echo=FALSE, results='hide', message=FALSE}
fontsize <- theme(axis.text=element_text(size=12), axis.title=element_text(size=16))
```

```{r pcaplotbrain, fig.width=12, fig.height=6, fig.cap="PCA plots constructed from the normalized expression values for all remaining cells in the brain data set. Each cell is represented by a point in each plot, and the bars represent the cell coordinates on each axis. Left: cells are coloured according to the tissue of origin (cortex or hippocampus). Right: cells are coloured according to the sex of the mouse -- male (-1), female (1) or unassigned (0)."}
pca1 <- plotPCA(sce, exprs_values="exprs", colour_by="tissue") + fontsize
pca2 <- plotPCA(sce, exprs_values="exprs", colour_by="sex") + fontsize
multiplot(pca1, pca2, cols=2)
```

Similar results are observed with _t_-SNE plots.
Again, users should set the seed to a constant value to ensure that the results are reproducible.

```{r tsneplotbrain, fig.width=12, fig.height=6, fig.cap="_t_-SNE plots constructed from the normalized expression values for all remaining cells in the brain data set. Each cell is represented by a point in each plot, and the bars represent the cell coordinates on each axis. Left: cells are coloured according to the tissue of origin (cortex or hippocampus). Right: cells are coloured according to the sex of the mouse -- male (-1), female (1) or unassigned (0)."}
set.seed(100)
tsne1 <- plotTSNE(sce, exprs_values="exprs", colour_by="tissue") + fontsize
set.seed(100)
tsne2 <- plotTSNE(sce, exprs_values="exprs", colour_by="sex") + fontsize
multiplot(tsne1, tsne2, cols=2)
```

An additional effect to consider is the fact that cells were processed on many different C1 chips.
This can lead to batch effects due to technical differences in library preparation between chips.
To check that this is not the case, we examine the spread of cells from each chip on the PCA plot.
Cells from different chips seem to mix together, which suggests that the substructure is not being driven by a batch effect.

```{r pca2plotbrain, fig.width=15, fig.height=6, fig.cap="PCA plots constructed from the normalized expression values for all cells in the brain data set from the cortex (left) or hippocampus (right). Each cell is represented by a point in each plot, and the bars represent the cell coordinates on each axis. Cells are coloured according to the C1 chip from which the library was prepared."}
sce$chip <- sub("_.*", "", sce$cell_id)
pca1 <- plotPCA(sce[,sce$tissue=="sscortex"], exprs_values="exprs", 
    colour_by="chip") + fontsize + ggtitle("Cortex")
pca2 <- plotPCA(sce[,sce$tissue!="sscortex"], exprs_values="exprs", 
    colour_by="chip") + fontsize + ggtitle("Hippocampus")
multiplot(pca1, pca2, cols=2)
```

Note that we separate cells by tissue to avoid picking up the tissue effect in the PCA plots (as the chip factor is nested within the tissue factor).
This hierarchical approach can be extended if sufficient annotation is available.
For example, consider a situation where multiple chips were used for each mouse, and multiple mice were used in the entire experiment.
We could construct a PCA plot for cells in each mouse, coloured by the chip of origin -- this allows us to check whether chip effects are present in that mouse.
We could then construct a PCA plot for all cells, coloured by the mouse of origin -- this allows us to check whether a mouse effect is present.
This strategy reduces the complexity of the colours in each plot and improves the ease of diagnosis.

<!-- 
The prefix of the cell ID seems to be the chip, as the second half of the ID marks the well position and there's always less than 96.
It should at least be the mouse, as the prefix is nested in tissue/sex. 
-->

In summary, the major difference between cells seems to be associated with the tissue of origin.
Whether this is interesting or not is debatable as it depends on the biological hypothesis being studied.
However, for the purposes of this workflow, we will treat the tissue of origin as an uninteresting confounding effect.
As such, we will block on tissue in all of our downstream analyses.

```{r}
design <- model.matrix(~sce$tissue)
```

## Identifying correlated HVGs

```{r}
var.fit <- trendVar(sce, trend="loess", design=design, span=0.5)
var.out <- decomposeVar(sce, var.fit)
plot(var.out$mean, var.out$total, pch=16, cex=0.6, xlab="Mean log-expression", 
    ylab="Variance of log-expression")
points(var.fit$mean, var.fit$var, col="red", pch=16)
o <- order(var.out$mean)
lines(var.out$mean[o], var.out$tech[o], col="red", lwd=2)
var.fit2 <- trendVar(sce, trend="loess", use.spikes=FALSE, design=design)
var.out2 <- decomposeVar(sce, var.fit2)
lines(var.out2$mean[o], var.out2$tech[o], col="dodgerblue", lwd=2)


set.seed(100)
top.hvgs <- order(var.out$bio, decreasing=TRUE)[1:200]
var.cor <- correlatePairs(y[top.hvgs,])

heat.vals <- assay(y, "exprs")
heat.vals <- heat.vals - rowMeans(heat.vals)
is.sig <- var.cor$FDR <= 0.05 
chosen <- unique(c(var.cor$gene1[is.sig], var.cor$gene2[is.sig]))
heatmap.2(heat.vals[chosen,], col=bluered, symbreak=TRUE, trace='none', cexRow=0.5)
```

## Defining subpopulations and detecting marker genes

# Choosing between normalization with and without spike-ins

## Overview
Scaling normalization strategies for scRNA-seq data can be broadly divided into two classes.
The first class assumes that there exists a subset of genes that are not differentially expressed between samples.
This subset can be manually specified to contain house-keeping genes, or it can be empirically identified under the assumption that most genes are not DE [@anders2010differential;@robinson2010scaling].
Any systematic difference in the counts across the non-DE subset is treated as technical bias and is eliminated by scaling.
The second class of normalization strategies uses spike-in RNA of known composition and abundance.
Specifically, the same quantity of spike-in RNA is added to each cell, captured into libraries and sequenced along with endogenous transcripts [@stegle2015computational].
Differences in the coverage of the spike-in transcripts can only be due to cell-specific biases, e.g., in capture efficiency or sequencing depth.
Scaling normalization is then applied to equalize spike-in coverage across cells.

The choice between these two normalization strategies depends on the biology of the cells and the features of interest.
If there is no reliable house-keeping set, and if the majority of genes are expected to be DE, then spike-in normalization may be the only option for removing technical biases.
Spike-in normalization should also be used if differences in the total RNA content of individual cells are of interest.
This is because the same amount of spike-in RNA is added to each cell, such that the relative quantity of endogenous RNA can be easily quantified in each cell.
For non-DE normalization, any change in total RNA content will affect all genes in the non-DE subset, such that it will be treated as bias and removed.
(This may be desirable if changes in total content are _not_ interesting.)
Similarly, if spike-ins are not present or if they cannot be added to each cell in a reliable manner, then non-DE normalization should be applied.

## Computing size factors for spike-in normalization

The use of spike-in normalization can be demonstrated on a simple data set comparing mESCs and mouse embryonic fibroblasts (MEFs) [@islam2011characterization].
A constant quantity of synthetic spike-in RNA was added to each cell, and spike-in transcripts were sequenced and counted along with transcripts from endogenous genes.
Quantification of gene expression was performed in this manner for 48 mESCs, 44 MEFs and 4 negative controls.
We obtain a table of read counts from NCBI GEO using the accession GSE29087, and load them into a `SummarizedExperiment` object for further manipulation.

```{r, eval=FALSE}
#```{r}
counts <- read.table("GSE29087_L139_expression_tab.txt.gz", skip=6, 
    sep='\t', row.names=1)[,-c(1:6)]
is.spike <- grepl("SPIKE", rownames(counts))
sum(is.spike)
library(scran)
y <- countsToSE(counts[!is.spike,], counts[is.spike,])
y$grouping <- factor(rep(c("mESC", "MEF", "Neg"), c(48, 44, 4)))
dim(y)
```

We remove low-quality libraries that have low total counts for the endogenous genes or high proportions of reads mapped to genes on the mitochondrial genome.
This removes a number of libraries, including those for the negative controls.
We also remove lowly expressed genes with an average count below 1.

```{r, eval=FALSE}
#```{r}
totals <- colSums(assay(y))
is.mito <- grepl("^mt-", rownames(y))
okay.libs <- totals >= 1e5 & colSums(assay(y)[is.mito,])/totals < 0.1 
y <- y[,okay.libs]
sum(okay.libs)
keep.gene <- rowMeans(assay(y)) >= 1
y <- y[keep.gene,] 
sum(keep.gene)
```

We compute size factors using the `normalizeBySpikes` function.
The size factor for each cell is proportional to the total number of reads mapped to spike-in transcripts.
The aim is to normalize the counts such that the total spike-in coverage is the same across cells.
These values are stored in the `SummarizedExperiment` object as previously described, and downstream analyses can be applied.

```{r, eval=FALSE}
#```{r}
sf.spike <- normalizeBySpikes(y)
y$size.factor <- sf.spike
````

Note that mESCs have consistently larger size factors compared to MEFs.
This is due to the fact that the former contain substantially less endogenous RNA than the latter [@islam2011characterization].
Larger size factors result in smaller normalized expression values for mESCs compared to MEFs, reflecting the decrease in total RNA content in the former.
These differences are lost when a normalization method based on a non-DE majority is applied, such as that in the `r Biocpkg("DESeq2")` package [@anders2010differential].

```{r, eval=FALSE}
#```{r}
y$grouping <- droplevels(y$grouping)
boxplot(split(sf.spike, y$grouping), log="y", cex.axis=1.2, cex.lab=1.4)
library(DESeq2)
y2 <- y
y2$size.factor <- estimateSizeFactorsForMatrix(assay(y2))
boxplot(split(y2$size.factor, y$grouping), log="y", cex.axis=1.2, 
    cex.lab=1.4, ylim=range(sf.spike))
```

## Effect of spike-in normalization on downstream analyses

Preservation of differences in total RNA content has some notable implications for downstream analyses.
For DEG detection between cell types, the change in total RNA content will be incorporated into the log-fold change.
This means that more DEGs are generally detected upon spike-in normalization compared to normalization based on a non-DE majority.
In addition, there tends to be a greater imbalance in the number of up- and downregulated genes, as the change in total RNA content occurs in one direction for all genes.
This is demonstrated below by comparing the DE results between the two normalization strategies. 

```{r, eval=FALSE}
#```{r}
library(edgeR)
d <- DGEList(assay(y, "counts"))
d$offset <- log(y$size.factor)
design <- model.matrix(~y$grouping)
d <- estimateDisp(d, design)
fit <- glmFit(d, design)
res <- glmLRT(fit)
summary(decideTestsDGE(res))
d2 <- d
d2$offset <- log(y2$size.factor)
d2 <- estimateDisp(d2, design)
fit2 <- glmFit(d2, design)
res2 <- glmLRT(fit2)
summary(decideTestsDGE(res2))
```

One might question the relevance of DE that is driven by changes in total RNA content between cell types.
Clearly, however, there will be a change in transcript abundance when the total amount of RNA in each cell changes.
Thus, from a technical perspective, the detection of DE for those genes is appropriate.
Biologically, the relevance of DE would depend on whether an increase in transcript molecules results in more molecular activity, e.g., due to increased production of protein product.
While this relation seems trivially true, it is easy to imagine situations where it is not the case, e.g., when the translation machinery is saturated such that a global increase in transcript molecules has no effect.

<!-- Also, if there's variability in cell sizes within groups, this'll reduce power to detect DEGs. -->

For HVG detection, any variability in total RNA content will inflate the variance of the normalized expression values for each gene.
However, the magnitude of the increase will be the same for each gene as the variance of RNA content is constant.
As such, the ranking of HVGs will be roughly similar across the different normalization strategies.
This is demonstrated below, where there is 70-80\% similarity between the top sets of 500-2000 genes with the largest variances from each normalization method.

```{r, eval=FALSE}
#```{r}
y <- normalize(y)
trend <- trendVar(y, use.spikes=FALSE, trend="loess")
resid.var <- trend$var - trend$trend(trend$mean)
y2 <- normalize(y2)
trend2 <- trendVar(y2, use.spikes=FALSE, trend="loess")
resid.var2 <- trend2$var - trend2$trend(trend2$mean)
r <- rank(-resid.var)
r2 <- rank(-resid.var2)
sum(r <= 500 & r2 <= 500)
sum(r <= 1000 & r2 <= 1000)
sum(r <= 2000 & r2 <= 2000)
```

<!-- don't subtract spike-ins here, as there's only 8 of them so it's not very reliable. -->

Most dimensionality reduction and clustering procedures tend to be robust to the choice of normalization method.
This is because cells with different RNA content also tend to have different transcript compositions.
Thus, they would be (correctly) separated based on their gene expression profiles, regardless of whether changes in total RNA content were preserved after normalization.
Indeed, correlation-based methods are completely insensitive to normalization as the value of the correlation is not dependent on the scaling of expression values within each cell.

```{r, eval=FALSE}
#```{r, fig.width=12, fig.height=6}
par(mfrow=c(1,2))
col <- c("red", "blue")[y$grouping]
out <- prcomp(t(assay(y, "exprs")), scale.=TRUE)
plot(out$x[,1], out$x[,2], col=col, pch=16, xlab="PC1", ylab="PC2")
out2 <- prcomp(t(assay(y2, "exprs")), scale.=TRUE)
plot(out2$x[,1], out2$x[,2], col=col, pch=16, xlab="PC1", ylab="PC2")
```

## Classifying cells into cell cycle phases

## Detecting DEGs between pre-defined groups of cells

# Conclusions

# Software availability

```{r}
sessionInfo()
```

# Author contributions

A.T.L.L. developed the workflow on all data sets.

# Competing interests

No competing interests were disclosed.

# Grant information

CRUK core funding (SW73) to J.C.M.

# Acknowledgements

Aaron is pretty awesome.

# References

